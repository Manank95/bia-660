{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of dtm: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "size of tfidf matrix: (1818, 5396)\n",
      "(5396,)\n",
      "[('fis', 0.39344147812556318), ('learning fis', 0.39344147812556318), ('machine learning fis', 0.39344147812556318), ('scientist machine learning', 0.31157194420991735), ('scientist machine', 0.31157194420991735), ('data scientist machine', 0.31157194420991735), ('machine learning', 0.25984478295418828), ('machine', 0.25984478295418828), ('learning', 0.2576917508453957), ('data scientist', 0.12364983569407609), ('scientist', 0.12003734172017579), ('data', 0.11505770043621663), ('facilities', 0.0), ('facilitatorproblem', 0.0), ('facilitatorproblem tacklerparadigm', 0.0), ('facilitatorproblem tacklerparadigm constructor', 0.0), ('facilities management expert', 0.0), ('facilities construction', 0.0), ('facilities management', 0.0), ('factory', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def performance_evaluate(filename):\n",
    "    with open(filename, \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "        reader = csv.reader(f, delimiter=',')    \n",
    "        text = [(row[1]) for row in reader]\n",
    "    #print(reader[0:2])\n",
    "    tfidf_vect = TfidfVectorizer(input = text,encoding='utf-8',decode_error='replace',stop_words=\"english\", ngram_range=(1,3))\n",
    "    dtm= tfidf_vect.fit_transform(text)\n",
    "    print(\"type of dtm:\", type(dtm))\n",
    "    print(\"size of tfidf matrix:\", dtm.shape)\n",
    "    voc_lookup={tfidf_vect.vocabulary_[word]:word \\\n",
    "            for word in tfidf_vect.vocabulary_}\n",
    "    \n",
    "    doc0=dtm[0].toarray()[0]\n",
    "    print(doc0.shape)\n",
    "\n",
    "    # get index of top 20 words\n",
    "    top_words=(doc0.argsort())[::-1][0:20]\n",
    "    print([(voc_lookup[i], doc0[i]) for i in top_words])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    performance_evaluate(\"indeed_scraped_data_science.csv\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
