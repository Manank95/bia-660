{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment 4 : Text Processing </center>\n",
    "\n",
    "Requirements:\n",
    "\n",
    "1. Define a function \"**tokenize**\" as follows:\n",
    "   - takes a string as an input\n",
    "   - converts the string into lowercase\n",
    "   - tokenizes the lowercased string into tokens. Each token has at least two characters. A token **only contains letters (i.e. a-z or A-Z), \"-\" (hyphen), or \"_\" (underscore)**. Moreover, ** a token cannot starts or ends with \"-\" or \"_\" **. \n",
    "   - removes stop words from the tokens (use English stop words list from NLTK)\n",
    "   - returns the resulting token list as the output\n",
    "   \n",
    "2. Define a function \"**sentiment_analysis**\" as follows:\n",
    "   - takes a string, a list of positive words, and a list of negative words as inputs. Assume the lists are read from positive-words.txt and negative-words.txt outside of this function.\n",
    "   - tokenize the string using NLTK word tokenizer\n",
    "   - counts positive words and negative words in the tokens using the positive/negative words lists. The final positive/negative words are defined as follows:\n",
    "     - Positive words:\n",
    "       * a positive word not preceded by a negation word (i.e. not, n't, no, cannot, neither, nor, too)\n",
    "       * a negative word preceded by a negation word\n",
    "     - Negative words:\n",
    "       * a negative word not preceded by a negation word\n",
    "       * a positive word preceded by a negation word\n",
    "   - determines the sentiment of the string as follows:\n",
    "     - 2: number of positive words > number of negative words\n",
    "     - 1: number of positive words <= number of negative words\n",
    "   - returns the sentiment \n",
    "    \n",
    "3. Define a function called **performance_evaluate** to evaluate the accuracy of the sentiment analysis in (2) as follows: \n",
    "   - takes an input file (\"amazon_review_300.csv\"), a list of positive words, and a list of negative words as inputs. The input file has a list of reviews in the format of (label, title, review). Use label (either '2' or '1') and review columns (i.e. columns 1 and 3 only) here.\n",
    "   - reads the input file to get reviews as a list of (label, reviews) tuples\n",
    "   - for each review, predicts its sentiment using the function defined in (2), and compare the prediction with its label\n",
    "   - returns the accuracy as the number of correct sentiment predictions/total reviews\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manank Valand - 10429101\n",
    "# references: lecture notes - Natural Language Processing I.ipynb, Regular_Expression.ipynb and Python_II.ipynb (for csv)\n",
    "#\n",
    "# wait for 2-3 seconds to get full output, because it takes time to read and apply calculations on \n",
    "# whole bunch of texts for couple of times\n",
    "#\n",
    "# PUT all required files for this assignment in the same path of this program. \n",
    "# Or change path values in driver program (__main__) \n",
    "\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens=[]\n",
    "    # write your code here\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = text.lower()\n",
    "    #print(text)\n",
    "    #pattern = r'\\w'\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token for token in tokens if re.match(\"^[A-Za-z_-]*$\", token)]\n",
    "    #print(tokens)\n",
    "    # to remove punctuations from begging and starting of the tokens \n",
    "    tokens = [token.strip(string.punctuation) for token in tokens]\n",
    "    # now removing extra empty characters from tokens\n",
    "    tokens = [token.strip() for token in tokens if token.strip()!='']\n",
    "    tokens = [token for token in tokens if len(token)>1]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def sentiment_analysis(text, positive_words, negative_words):\n",
    "    \n",
    "    sentiment=None\n",
    "    negations=['not', 'too', 'n\\'t', 'no', 'cannot', 'neither', 'nor']\n",
    "    # write your code here\n",
    "    tokens = tokenize(text)\n",
    "    #print(tokens)\n",
    "    positive_tokens =[]\n",
    "    negative_tokens =[]\n",
    "    for idx, token in enumerate(tokens):\n",
    "        if token in positive_words:\n",
    "            if(idx>0):\n",
    "                if tokens[idx-1] not in negations:\n",
    "                    positive_tokens.append(token)\n",
    "                else:\n",
    "                    negative_tokens.append(token)\n",
    "            else:\n",
    "                positive_tokens.append(token)\n",
    "        elif token in negative_words:\n",
    "            if(idx>0):\n",
    "                if tokens[idx-1] not in negations:\n",
    "                    negative_tokens.append(token)\n",
    "                else:\n",
    "                    positive_tokens.append(token)\n",
    "            else:\n",
    "                negative_tokens.append(token)\n",
    "    #remove below 2 comments to check the array built out of provided string\n",
    "    #print(\"positive tokens:\",positive_tokens)\n",
    "    #print(\"negative tokens:\",negative_tokens)\n",
    "    \n",
    "    if len(positive_tokens)>len(negative_tokens):\n",
    "        sentiment = 2\n",
    "    else:\n",
    "        sentiment = 1\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "def performance_evaluate(input_file, positive_words, negative_words):\n",
    "    \n",
    "    accuracy=None\n",
    "    cnt=0\n",
    "    # write your code here\n",
    "    with open(input_file, \"r\") as f:\n",
    "        reader=csv.reader(f, delimiter=',')\n",
    "        rows=[(row[0], row[2]) for row in reader]\n",
    "    row_len = len(rows)\n",
    "    #print(row_len)\n",
    "    for i in rows:\n",
    "        if int(i[0]) == sentiment_analysis(i[1], positive_words, negative_words):\n",
    "            cnt+=1\n",
    "    \n",
    "    #print(cnt)\n",
    "    accuracy = cnt/row_len\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens:\n",
      "['breath-taking', 'ambitious', 'movie', 'test', 'text', 'abc_dcd', 'abc', 'abc-dcd', 'abc']\n",
      "\n",
      "sentiment\n",
      "2\n",
      "\n",
      "accuracy\n",
      "0.71\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    text=\"This is a breath-taking ambitious movie; test text: abc_dcd abc_ dvr89w, abc-dcd -abc\"\n",
    "\n",
    "    tokens=tokenize(text)\n",
    "    print(\"tokens:\")\n",
    "    print(tokens)\n",
    "    \n",
    "    \n",
    "    with open(\"positive-words.txt\",'r') as f:\n",
    "        positive_words=[line.strip() for line in f]\n",
    "        \n",
    "    with open(\"negative-words.txt\",'r') as f:\n",
    "        negative_words=[line.strip() for line in f]\n",
    "    #print(positive_words)  \n",
    "    print(\"\\nsentiment\")\n",
    "    sentiment=sentiment_analysis(text, positive_words, negative_words)\n",
    "    print(sentiment)\n",
    "    \n",
    "    accuracy=performance_evaluate(\"amazon_review_300.csv\", positive_words, negative_words)\n",
    "    print(\"\\naccuracy\")\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
