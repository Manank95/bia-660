{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of dtm: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "size of tfidf matrix: (1818, 29670)\n",
      "['1', '2', '3']\n",
      "[ 0.58991228  1.          0.68965517]\n",
      "[ 0.9676259   0.45522388  0.14925373]\n",
      "[ 0.73297003  0.62564103  0.24539877]\n",
      "[278 134 134]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.97      0.73       278\n",
      "          2       1.00      0.46      0.63       134\n",
      "          3       0.69      0.15      0.25       134\n",
      "\n",
      "avg / total       0.72      0.64      0.59       546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# import method for split train/test data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import method to calculate metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# initialize the TfidfVectorizer \n",
    "\n",
    "\n",
    "\n",
    "with open(\"indeed_scraped_data_science.csv\", \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    text = [(row[8]) for row in reader]\n",
    "    \n",
    "with open(\"indeed_scraped_data_science.csv\", \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    target = [(row[0]) for row in reader]\n",
    "\n",
    "\n",
    "# convert tuple to list\n",
    "text=list(text)\n",
    "#print(len(text))\n",
    "\n",
    "## all labels\n",
    "target=list(target)\n",
    "#print(len(target))\n",
    "\n",
    "#print(target[0:10])\n",
    "\n",
    "tfidf_vect = TfidfVectorizer() \n",
    "\n",
    "# with stop words removed\n",
    "#tfidf_vect = TfidfVectorizer(stop_words=\"english\") \n",
    "\n",
    "# generate tfidf matrix\n",
    "dtm= tfidf_vect.fit_transform(text)\n",
    "\n",
    "print(\"type of dtm:\", type(dtm))\n",
    "print(\"size of tfidf matrix:\", dtm.shape)\n",
    "\n",
    "# split dataset into train (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "                dtm, target, test_size=0.3, random_state=0)\n",
    "\n",
    "# train a multinomial naive Bayes model using the testing data\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "# predict the news group for the test dataset\n",
    "predicted=clf.predict(X_test)\n",
    "\n",
    "# get the list of unique labels\n",
    "labels=sorted(list(set(target)))\n",
    "\n",
    "# calculate performance metrics. \n",
    "# Support is the number of occurrences of each label\n",
    "\n",
    "precision, recall, fscore, support=\\\n",
    "     precision_recall_fscore_support(\\\n",
    "     y_test, predicted, labels=labels)\n",
    "\n",
    "print(labels)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(fscore)\n",
    "print(support)\n",
    "\n",
    "# another way to get all performance metrics\n",
    "print(classification_report(y_test, predicted, target_names=labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 28026)\n",
      "\"I'm a Vice President Vice President Vice President Vice President / Fashion designer of my own company. I design clothing and fashion ranges.\" => 3\n",
      "'Developed client module to be used in Windows environment in C++, MFC, COM, TCP/IP Sockets' => 2\n",
      "'Designed and developed a demonstration system that includes all of the options and security features that are available' => 1\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['I\\'m a Vice President Vice President Vice President Vice President / Fashion designer of my own company. I design clothing and fashion ranges.','Developed client module to be used in Windows environment in C++, MFC, COM, TCP/IP Sockets', 'Designed and developed a demonstration system that includes all of the options and security features that are available']\n",
    "\n",
    "#Responsibilities: Costing, estimating and planning projects.\n",
    "# generate tifid for new documents\n",
    "X_new_tfidf = tfidf_vect.transform(docs_new)\n",
    "\n",
    "print(X_new_tfidf.shape)\n",
    "\n",
    "# predict classes for new documents\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for idx, doc in enumerate(docs_new):\n",
    "    print('%r => %s' % (doc, predicted[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1818, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '3'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([923, 454, 441])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y=mlb.fit_transform(target)\n",
    "# check size of indicator matrix\n",
    "Y.shape\n",
    "# check classes\n",
    "mlb.classes_\n",
    "\n",
    "# check # of samples in each class\n",
    "np.sum(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['description', 'fis', 'provides', 'financial', 'software', 'world-class', 'services', 'and', 'global', 'business', 'solutions', 'let', 'us', 'help', 'you', 'compete', 'and', 'win', 'in', 'today', 'chaotic', 'marketplace', 'fidelity', 'national', 'information', 'services', 'inc', 'better', 'known', 'by', 'the', 'abbreviation', 'fis', 'is', 'an', 'international', 'provider', 'of', 'financial', 'services', 'technology', 'and', 'outsourcing', 'services', 'fis', 'is', 'the', 'world', 'largest', 'global', 'provider', 'dedicated', 'to', 'financial', 'technology', 'solutions', 'fis', 'empowers', 'the', 'financial', 'world', 'with', 'software', 'services', 'consulting', 'and', 'outsourcing', 'solutions', 'focused', 'on', 'retail', 'and', 'institutional', 'banking', 'payments', 'asset', 'and', 'wealth', 'management', 'risk', 'and', 'compliance', 'trade', 'enablement', 'transaction', 'processing', 'and', 'record-keeping', 'responsibilities', 'extracted', 'data', 'from', 'hdfs', 'and', 'prepared', 'data', 'for', 'exploratory', 'analysis', 'using', 'data', 'munging', 'built', 'models', 'using', 'statistical', 'techniques', 'like', 'bayesian', 'hmm', 'and', 'machine', 'learning', 'classification', 'models', 'like', 'xgboost', 'svm', 'and', 'random', 'forest', 'participated', 'in', 'all', 'phases', 'of', 'data', 'mining', 'data', 'cleaning', 'data', 'collection', 'developing', 'models', 'validation', 'visualization', 'and', 'performed', 'gap', 'analysis', 'highly', 'immersive', 'data', 'science', 'program', 'involving', 'data', 'manipulation', 'visualization', 'web', 'scraping', 'machine', 'learning', 'python', 'programming', 'sql', 'git', 'mongodb', 'hadoop', 'setup', 'storage', 'and', 'data', 'analysis', 'tools', 'in', 'aws', 'cloud', 'computing', 'infrastructure', 'installed', 'and', 'used', 'caffe', 'deep', 'learning', 'framework', 'worked', 'on', 'different', 'data', 'formats', 'such', 'as', 'json', 'xml', 'and', 'performed', 'machine', 'learning', 'algorithms', 'in', 'python', 'worked', 'as', 'data', 'architects', 'and', 'it', 'architects', 'to', 'understand', 'the', 'movement', 'of', 'data', 'and', 'its', 'storage', 'and', 'er', 'studio', '9.7', 'used', 'pandas', 'numpy', 'seaborn', 'matplotlib', 'scikit-learn', 'scipy', 'nltk', 'in', 'python', 'for', 'developing', 'various', 'machine', 'learning', 'algorithms', 'data', 'manipulation', 'and', 'aggregation', 'from', 'different', 'source', 'using', 'nexus', 'business', 'objects', 'toad', 'power', 'bi', 'and', 'smart', 'view', 'implemented', 'agile', 'methodology', 'for', 'building', 'an', 'internal', 'application', 'focus', 'on', 'integration', 'overlap', 'and', 'informatica', 'newer', 'commitment', 'to', 'mdm', 'with', 'the', 'acquisition', 'of', 'identity', 'systems', 'coded', 'proprietary', 'packages', 'to', 'analyze', 'and', 'visualize', 'spcfile', 'data', 'to', 'identify', 'bad', 'spectra', 'and', 'samples', 'to', 'reduce', 'unnecessary', 'procedures', 'and', 'costs', 'programmed', 'utility', 'in', 'python', 'that', 'used', 'multiple', 'packages', 'numpy', 'scipy', 'pandas', 'implemented', 'classification', 'using', 'supervised', 'algorithms', 'like', 'logistic', 'regression', 'decision', 'trees', 'naive', 'bayes', 'knn', 'as', 'architect', 'delivered', 'various', 'complex', 'olapdatabases/cubes', 'scorecards', 'dashboards', 'and', 'reports', 'updated', 'python', 'scripts', 'to', 'match', 'training', 'data', 'with', 'our', 'database', 'stored', 'in', 'aws', 'cloud', 'search', 'so', 'that', 'we', 'would', 'be', 'able', 'to', 'assign', 'each', 'document', 'response', 'label', 'for', 'further', 'classification', 'used', 'teradata', 'utilities', 'such', 'as', 'fast', 'export', 'mload', 'for', 'handling', 'various', 'tasks', 'data', 'migration/etl', 'from', 'oltp', 'source', 'systems', 'to', 'olap', 'target', 'systems', 'data', 'transformation', 'from', 'various', 'resources', 'data', 'organization', 'features', 'extraction', 'from', 'raw', 'and', 'stored', 'validated', 'the', 'machine', 'learning', 'classifiers', 'using', 'roc', 'curves', 'and', 'lift', 'charts', 'environment', 'unix', 'python', '3.5.2', 'mllib', 'sas', 'regression', 'logistic', 'regression', 'hadoop', '2.7.4', 'nosql', 'teradata', 'oltp', 'random', 'forest', 'olap', 'hdfs', 'ods', 'nltk', 'svm', 'json', 'xml', 'and', 'mapreduce', 'description', 'cbre', 'group', 'inc', 'is', 'the', 'largest', 'commercial', 'real', 'estate', 'services', 'and', 'investment', 'firm', 'in', 'the', 'world', 'it', 'is', 'based', 'in', 'los', 'angeles', 'california', 'and', 'operates', 'more', 'than', '450', 'offices', 'worldwide', 'and', 'has', 'clients', 'in', 'more', 'than', '100', 'countries', 'responsibilities', 'utilized', 'spark', 'scala', 'hadoop', 'hql', 'vql', 'oozie', 'pyspark', 'data', 'lake', 'tensorflow', 'hbase', 'cassandra', 'redshift', 'mongodb', 'kafka', 'kinesis', 'spark', 'streaming', 'edward', 'cuda', 'mllib', 'aws', 'python', 'broad', 'variety', 'of', 'machine', 'learning', 'methods', 'including', 'classifications', 'regressions', 'dimensionally', 'reduction', 'etc', 'utilized', 'the', 'engine', 'to', 'increase', 'user', 'lifetime', 'by', '45', 'and', 'triple', 'user', 'conversations', 'for', 'target', 'categories', 'application', 'of', 'various', 'machine', 'learning', 'algorithms', 'and', 'statistical', 'modeling', 'like', 'decision', 'trees', 'text', 'analytics', 'natural', 'language', 'processing', 'nlp', 'supervised', 'and', 'unsupervised', 'regression', 'models', 'social', 'network', 'analysis', 'neural', 'networks', 'deep', 'learning', 'svm', 'clustering', 'to', 'identify', 'volume', 'using', 'scikit-learn', 'package', 'in', 'python', 'matlab', 'worked', 'onanalyzing', 'data', 'from', 'google', 'analytics', 'adwords', 'facebook', 'etc', 'evaluated', 'models', 'using', 'cross', 'validation', 'log', 'loss', 'function', 'roc', 'curves', 'and', 'used', 'auc', 'for', 'feature', 'selection', 'and', 'elastic', 'technologies', 'like', 'elasticsearch', 'kibana', 'performed', 'data', 'profiling', 'to', 'learn', 'about', 'behavior', 'with', 'various', 'features', 'such', 'as', 'traffic', 'pattern', 'location', 'date', 'and', 'time', 'etc', 'categorized', 'comments', 'into', 'positive', 'and', 'negative', 'clusters', 'from', 'different', 'social', 'networking', 'sites', 'using', 'sentiment', 'analysis', 'and', 'text', 'analytics', 'performed', 'multinomial', 'logistic', 'regression', 'decision', 'tree', 'random', 'forest', 'svm', 'to', 'classify', 'package', 'is', 'going', 'to', 'deliver', 'on', 'time', 'for', 'the', 'new', 'route', 'performed', 'data', 'analysis', 'by', 'using', 'hive', 'to', 'retrieve', 'the', 'data', 'from', 'hadoop', 'cluster', 'sql', 'to', 'retrieve', 'datafrom', 'oracle', 'database', 'and', 'used', 'etl', 'for', 'data', 'transformation', 'performed', 'data', 'cleaning', 'features', 'scaling', 'features', 'engineering', 'using', 'pandas', 'and', 'numpy', 'packages', 'in', 'python', 'exploring', 'dag', 'their', 'dependencies', 'and', 'logs', 'using', 'airflow', 'pipelines', 'for', 'automation', 'performed', 'data', 'cleaning', 'and', 'feature', 'selection', 'using', 'mllib', 'package', 'in', 'pyspark', 'and', 'working', 'with', 'deep', 'learning', 'frameworks', 'such', 'as', 'caffe', 'neon', 'developed', 'spark/scala', 'python', 'for', 'regular', 'expression', 'regex', 'project', 'in', 'the', 'hadoop/hive', 'environment', 'with', 'linux/windows', 'for', 'big', 'data', 'resources', 'used', 'clustering', 'technique', 'k-means', 'to', 'identify', 'outliers', 'and', 'to', 'classify', 'unlabeled', 'data', 'tracking', 'operations', 'using', 'sensors', 'until', 'certain', 'criteria', 'is', 'met', 'using', 'airflowtechnology', 'responsible', 'for', 'different', 'data', 'mapping', 'activities', 'from', 'source', 'systems', 'to', 'teradata', 'using', 'utilities', 'like', 'tpump', 'fexp', 'bteq', 'mload', 'floadetc', 'analyze', 'traffic', 'patterns', 'by', 'calculating', 'autocorrelation', 'with', 'different', 'time', 'lags', 'ensured', 'that', 'the', 'model', 'has', 'low', 'false', 'positive', 'rate', 'and', 'text', 'classification', 'and', 'sentiment', 'analysis', 'for', 'unstructured', 'and', 'semi-structured', 'data', 'addressed', 'over', 'fitting', 'by', 'implementing', 'of', 'the', 'algorithm', 'regularization', 'methods', 'like', 'l1', 'and', 'l2', 'used', 'principal', 'component', 'analysis', 'in', 'feature', 'engineering', 'to', 'analyze', 'high', 'dimensional', 'data', 'used', 'mllib', 'spark', 'machine', 'learning', 'library', 'to', 'build', 'and', 'evaluate', 'different', 'models', 'implemented', 'rule', 'based', 'expertise', 'system', 'from', 'the', 'results', 'of', 'exploratory', 'analysis', 'and', 'information', 'gathered', 'from', 'the', 'people', 'from', 'different', 'departments', 'created', 'and', 'designed', 'reports', 'that', 'will', 'use', 'gathered', 'metrics', 'to', 'infer', 'and', 'draw', 'logical', 'conclusions', 'of', 'past', 'and', 'future', 'behavior', 'developed', 'mapreduce', 'pipeline', 'for', 'feature', 'extraction', 'using', 'hive', 'and', 'pig', 'created', 'data', 'quality', 'scripts', 'using', 'sql', 'and', 'hive', 'to', 'validate', 'successful', 'data', 'load', 'and', 'quality', 'of', 'the', 'data', 'created', 'various', 'types', 'of', 'data', 'visualizations', 'using', 'python', 'and', 'tableau', 'communicated', 'the', 'results', 'with', 'operations', 'team', 'for', 'taking', 'best', 'decisions', 'collected', 'data', 'needs', 'and', 'requirements', 'by', 'interacting', 'with', 'the', 'other', 'departments', 'environment', 'python', '2.x', 'cdh5', 'hdfs', 'hadoop', '2.3', 'hive', 'impala', 'aws', 'linux', 'spark', 'tableau', 'desktop', 'sql', 'server', '2014', 'microsoft', 'excel', 'matlab', 'spark', 'sql', 'pyspark', 'description', 'the', 'walgreens', 'companyis', 'an', 'american', 'company', 'that', 'operatesas', 'the', 'second-largest', 'pharmacy', 'store', 'chain', 'in', 'the', 'united', 'states', 'it', 'specializes', 'in', 'filling', 'prescriptions', 'health', 'and', 'wellness', 'products', 'health', 'information', 'and', 'photo', 'services', 'responsibilities', 'worked', 'with', 'bi', 'team', 'in', 'gathering', 'the', 'report', 'requirements', 'and', 'also', 'sqoop', 'to', 'export', 'data', 'into', 'hdfs', 'and', 'hive', 'involved', 'in', 'the', 'below', 'phases', 'of', 'analytics', 'using', 'python', 'and', 'jupyter', 'notebook', 'data', 'collection', 'and', 'treatment', 'analysed', 'existing', 'internal', 'data', 'and', 'external', 'data', 'worked', 'on', 'entry', 'errors', 'classification', 'errors', 'and', 'defined', 'criteria', 'for', 'missing', 'values', 'data', 'mining', 'used', 'cluster', 'analysis', 'for', 'identifying', 'customer', 'segments', 'decision', 'trees', 'used', 'for', 'profitable', 'and', 'non-profitable', 'customers', 'market', 'basket', 'analysis', 'used', 'for', 'customer', 'purchasing', 'behaviour', 'and', 'part/product', 'association', 'developed', 'multiple', 'map', 'reduce', 'jobs', 'in', 'java', 'for', 'data', 'cleaning', 'and', 'preprocessing', 'assisted', 'with', 'data', 'capacity', 'planning', 'and', 'node', 'forecasting', 'installed', 'configured', 'and', 'managed', 'flume', 'infrastructure', 'administrator', 'for', 'pig', 'hive', 'and', 'hbase', 'installing', 'updates', 'patches', 'and', 'upgrades', 'worked', 'closely', 'with', 'the', 'claims', 'processing', 'team', 'to', 'obtain', 'patterns', 'in', 'filing', 'of', 'fraudulent', 'claims', 'worked', 'on', 'performing', 'major', 'upgrade', 'of', 'cluster', 'from', 'cdh3u6', 'to', 'cdh4.4.0', 'developed', 'map', 'reduce', 'programs', 'to', 'extract', 'and', 'transform', 'the', 'data', 'sets', 'and', 'results', 'were', 'exported', 'back', 'to', 'rdbms', 'using', 'sqoop', 'patterns', 'were', 'observed', 'in', 'fraudulent', 'claims', 'using', 'text', 'mining', 'in', 'and', 'hive', 'exported', 'the', 'data', 'required', 'information', 'to', 'rdbms', 'using', 'sqoop', 'to', 'make', 'the', 'data', 'available', 'for', 'the', 'claims', 'processing', 'team', 'to', 'assist', 'in', 'processing', 'claim', 'based', 'on', 'the', 'data', 'developed', 'map', 'reduce', 'programs', 'to', 'parse', 'the', 'raw', 'data', 'populate', 'staging', 'tables', 'and', 'store', 'the', 'refined', 'data', 'in', 'partitioned', 'tables', 'in', 'the', 'edw', 'created', 'tables', 'in', 'hive', 'and', 'loaded', 'the', 'structured', 'resulted', 'from', 'map', 'reduce', 'jobs', 'data', 'using', 'hiveql', 'developed', 'many', 'queries', 'and', 'extracted', 'the', 'required', 'information', 'created', 'hive', 'queries', 'that', 'helped', 'market', 'analysts', 'spot', 'emerging', 'trends', 'by', 'comparing', 'fresh', 'data', 'with', 'edw', 'reference', 'tables', 'and', 'historical', 'metrics', 'was', 'responsible', 'for', 'importing', 'the', 'data', 'mostly', 'log', 'files', 'from', 'various', 'sources', 'into', 'hdfs', 'using', 'flume', 'enabled', 'speedy', 'reviews', 'and', 'first', 'mover', 'advantages', 'by', 'using', 'oozie', 'to', 'automate', 'data', 'loading', 'into', 'the', 'hadoop', 'distributed', 'file', 'system', 'and', 'pig', 'to', 'pre-process', 'the', 'data', 'provided', 'design', 'recommendations', 'and', 'thought', 'leadership', 'to', 'sponsors/stakeholders', 'that', 'improved', 'review', 'processes', 'and', 'resolved', 'technical', 'problems', 'managed', 'and', 'reviewed', 'hadoop', 'log', 'files', 'tested', 'raw', 'data', 'and', 'executed', 'performance', 'scripts', 'environment', 'hdfs', 'pig', 'hive', 'map', 'reduce', 'linux', 'hbase', 'flume', 'sqoop', 'vmware', 'eclipse', 'cloudera', 'python', 'description', 'transamerica', 'is', 'the', 'us-based', 'brand', 'of', 'aegon', 'dutch', 'financial', 'services', 'firm', 'aegon', 'is', 'one', 'of', 'the', 'world', 'leading', 'providers', 'of', 'life', 'insurance', 'pensions', 'and', 'asset', 'management', 'and', 'is', 'helping', 'approximately', '30', 'million', 'customers', 'globally', 'to', 'achieve', 'lifetime', 'of', 'financial', 'security', 'responsibilities', 'manipulating', 'cleansing', 'processing', 'data', 'using', 'excel', 'access', 'and', 'sql', 'responsible', 'for', 'loading', 'extracting', 'and', 'validation', 'of', 'client', 'data', 'modelled', 'clean', 'data', 'into', 'the', 'kafka', 'servers', 'for', 'use', 'over', 'the', 'spark', 'engine', 'zookeeper', 'along', 'with', 'kafka', 'was', 'used', 'to', 'stream', 'data', 'and', 'end-to-end', 'client', 'communication', 'performed', 'transformations', 'over', 'the', 'warehoused', 'data', 'using', 'scala', 'python', 'and', 'modelled', 'the', 'data', 'back', 'into', 'the', 'servers', 'for', 'iterative', 'transformations', 'into', 'kafka', 'modelled', 'data', 'using', 'machine', 'learning', 'libraries', 'sci-kit', 'learn', 'apart', 'from', 'svn', 'and', 'knn', 'based', 'classificationto', 'create', 'training', 'dataset', 'for', 'use', 'in', 'predictive', 'model', 'liaising', 'with', 'end-users', 'and', '3rd', 'party', 'suppliers', 'analyzing', 'raw', 'data', 'drawing', 'conclusions', 'developing', 'recommendations', 'writing', 't-sql', 'scripts', 'to', 'manipulate', 'data', 'for', 'data', 'loads', 'and', 'extracts', 'developing', 'data', 'analytical', 'databases', 'from', 'complex', 'financial', 'source', 'data', 'performing', 'daily', 'system', 'checks', 'data', 'entry', 'data', 'auditing', 'creating', 'data', 'reports', 'monitoring', 'all', 'data', 'for', 'accuracy', 'designing', 'developing', 'and', 'implementing', 'new', 'functionality', 'monitoring', 'the', 'automated', 'loading', 'processes', 'advising', 'on', 'the', 'suitability', 'of', 'methodologies', 'and', 'suggesting', 'improvements', 'carrying', 'out', 'specified', 'data', 'processing', 'and', 'statistical', 'techniques', 'supplying', 'qualitative', 'and', 'quantitative', 'data', 'to', 'colleagues', 'clients', 'using', 'informatica', 'sas', 'to', 'extract', 'transform', 'load', 'source', 'data', 'from', 'transaction', 'systems', 'performed', 'sequential', 'analytics', 'using', 'sas', 'enterprise', 'miner', 'using', 'jobs', 'fed', 'by', 'the', 'sas', 'grid', 'manager', 'loaded', 'packages', 'and', 'stored', 'procedures', 'using', 'base', 'sas', 'and', 'integrated', 'functional', 'and', 'business', 'requirements', 'using', 'the', 'ebi', 'suite', 'creating', 'data', 'pipelines', 'using', 'big', 'data', 'technologies', 'like', 'hadoop', 'spark', 'etc', 'creating', 'statistical', 'models', 'using', 'distributed', 'and', 'standalone', 'models', 'to', 'build', 'various', 'diagnostics', 'predictive', 'and', 'prescriptive', 'solution', 'utilize', 'broad', 'variety', 'of', 'statistical', 'packages', 'like', 'sas', 'mlib', 'graphs', 'hadoop', 'spark', 'mapreduce', 'pig', 'performed', 'check', 'using', 'quality', 'parameters', 'fed', 'using', 'the', 'sas', 'qc', 'engine', 'created', 'ui', 'dashboard', 'for', 'end', 'users', 'and', 'performed', 'prototype', 'testing', 'using', 'tableau', 'refine', 'and', 'train', 'models', 'based', 'on', 'domain', 'knowledge', 'and', 'customer', 'business', 'objectives', 'deliver', 'or', 'collaborate', 'on', 'delivering', 'effective', 'visualizations', 'to', 'support', 'the', 'client', 'business', 'objectives', 'communicate', 'to', 'your', 'peers', 'and', 'managers', 'promptly', 'as', 'and', 'when', 'required', 'produce', 'solid', 'and', 'effective', 'strategies', 'based', 'on', 'accurate', 'and', 'meaningful', 'data', 'reports', 'and', 'analysis', 'and/or', 'keen', 'observations', 'establish', 'and', 'maintain', 'communication', 'with', 'clients', 'and/or', 'team', 'members', 'understand', 'needs', 'resolve', 'issues', 'and', 'meet', 'expectations', 'developed', 'web', 'applications', 'using', 'net', 'technologies', 'work', 'on', 'bug', 'fixes/issues', 'that', 'arise', 'in', 'the', 'production', 'environment', 'and', 'resolve', 'them', 'at', 'the', 'earliest', 'environment', 'cloudera', 'hdfs', 'pig', 'hive', 'map', 'reduce', 'python', 'sqoop', 'storm', 'kafka', 'linux', 'hbase', 'impala', 'java', 'sql', 'cassandra', 'mongodb', 'svn', 'description', 'infotech', 'enterprises', 'it', 'services', 'pvt', 'ltd', 'infotech', 'it', 'part', 'of', 'the', '260', 'million', 'infotech', 'enterprises', 'group', 'leverages', 'its', 'business', 'process', 'knowledge', 'technological', 'competence', 'strategic', 'alliances', 'and', 'strong', 'global', 'presence', 'to', 'offer', 'innovative', 'it', 'solutions', 'to', 'the', 'retail', 'industry', 'responsibilities', 'worked', 'with', 'large', 'amounts', 'of', 'structured', 'and', 'unstructured', 'data', 'knowledge', 'in', 'machine', 'learning', 'concepts', 'generalized', 'linear', 'models', 'regularization', 'random', 'forest', 'time', 'series', 'models', 'etc', 'worked', 'in', 'business', 'intelligence', 'tools', 'and', 'visualization', 'tools', 'such', 'as', 'business', 'objects', 'tableau', 'chartio', 'etc', 'deployed', 'gui', 'pages', 'by', 'using', 'jsp', 'jstl', 'html', 'dhtml', 'xhtml', 'css', 'javascript', 'ajax', 'configured', 'the', 'project', 'on', 'websphere', '6.1', 'application', 'servers', 'implemented', 'the', 'online', 'application', 'by', 'using', 'core', 'java', 'jdbc', 'jsp', 'servlets', 'and', 'ejb', '1.1', 'web', 'services', 'soap', 'wsdl', 'handled', 'end-to-end', 'project', 'from', 'data', 'discovery', 'to', 'model', 'deployment', 'monitoring', 'the', 'automated', 'loading', 'processes', 'communicated', 'with', 'other', 'health', 'care', 'info', 'by', 'using', 'web', 'services', 'with', 'the', 'help', 'of', 'soap', 'wsdljax-rpc', 'used', 'singleton', 'factory', 'design', 'pattern', 'dao', 'design', 'patterns', 'based', 'on', 'the', 'application', 'requirements', 'used', 'sax', 'and', 'dom', 'parsers', 'to', 'parse', 'the', 'raw', 'xml', 'documents', 'used', 'rad', 'as', 'development', 'ide', 'for', 'web', 'applications', 'preparing', 'and', 'executing', 'unit', 'test', 'cases', 'used', 'log4j', 'logging', 'framework', 'to', 'write', 'log', 'messages', 'with', 'various', 'levels', 'involved', 'in', 'fixing', 'bugs', 'and', 'minor', 'enhancements', 'for', 'the', 'front-end', 'modules', 'implemented', 'microsoft', 'visio', 'and', 'rational', 'rose', 'for', 'designing', 'the', 'use', 'case', 'diagrams', 'class', 'model', 'sequence', 'diagrams', 'and', 'activity', 'diagrams', 'for', 'sdlc', 'process', 'of', 'the', 'application', 'doing', 'functional', 'and', 'technical', 'reviews', 'maintenance', 'in', 'the', 'testing', 'team', 'for', 'system', 'testing/integration/uat', 'guaranteeing', 'quality', 'in', 'the', 'deliverables', 'conducted', 'design', 'reviews', 'and', 'technical', 'reviews', 'with', 'other', 'project', 'stakeholders', 'was', 'part', 'of', 'the', 'complete', 'life', 'cycle', 'of', 'the', 'project', 'from', 'the', 'requirements', 'to', 'the', 'production', 'support', 'created', 'test', 'plan', 'documents', 'for', 'all', 'back-end', 'database', 'modules', 'implemented', 'the', 'project', 'in', 'linux', 'environment', 'environment', '3.0', 'erwin', '9.5', 'tableau', '8.0', 'mdm', 'qlikview', 'mllib', 'pl/sql', 'hdfs', 'teradata', '14.1', 'json', 'hadoop', 'hdfs', 'mapreduce', 'pig', 'spark', 'studio', 'mahout', 'java', 'hive', 'aws', 'description', 'globallogic', 'provides', 'experience', 'design', 'digital', 'product', 'engineering', 'services', 'and', 'agile', 'software', 'development', 'to', 'the', 'world', 'top', 'brands', 'by', 'leveraging', 'ux', 'ui', 'design', 'next-gen', 'technologies', 'and', 'cloud', 'software', 'with', 'end-to-end', 'solution', 'by', 'the', 'best', 'software', 'development', 'company', 'responsibilities', 'developed', 'internet', 'traffic', 'scoring', 'platform', 'for', 'ad', 'networks', 'advertisers', 'and', 'publishers', 'rule', 'engine', 'site', 'scoring', 'keyword', 'scoring', 'lift', 'measurement', 'linkage', 'analysis', 'responsible', 'for', 'defining', 'the', 'key', 'identifiers', 'for', 'each', 'mapping/interface', 'clients', 'include', 'ebay', 'click', 'forensics', 'cars.com', 'turn.com', 'microsoft', 'and', 'looksmart', 'designed', 'the', 'architecture', 'for', 'one', 'of', 'the', 'first', 'analytics', '3.0', 'online', 'platforms', 'all-purpose', 'scoring', 'with', 'on-demand', 'saas', 'api', 'services', 'currently', 'under', 'implementation', 'web', 'crawling', 'and', 'text', 'mining', 'techniques', 'to', 'score', 'referral', 'domains', 'generate', 'keyword', 'taxonomies', 'and', 'assess', 'commercial', 'value', 'of', 'bid', 'keywords', 'developed', 'new', 'hybrid', 'statistical', 'and', 'data', 'mining', 'technique', 'known', 'as', 'hidden', 'decision', 'trees', 'and', 'hidden', 'forests', 'reverse', 'engineering', 'of', 'keyword', 'pricing', 'algorithms', 'in', 'the', 'context', 'of', 'pay-per-click', 'arbitrage', 'implementation', 'of', 'metadata', 'repository', 'maintaining', 'data', 'quality', 'data', 'cleanup', 'procedures', 'transformations', 'data', 'standards', 'data', 'governance', 'program', 'scripts', 'stored', 'procedures', 'triggers', 'and', 'execution', 'of', 'test', 'plans', 'performed', 'data', 'quality', 'in', 'talend', 'open', 'studio', 'coordinated', 'meetings', 'with', 'vendors', 'to', 'define', 'requirements', 'and', 'system', 'interaction', 'agreement', 'documentation', 'between', 'client', 'and', 'vendor', 'system', 'automated', 'bidding', 'for', 'advertiser', 'campaigns', 'based', 'either', 'on', 'keyword', 'or', 'category', 'run-of-site', 'bidding', 'creation', 'of', 'multimillion', 'bid', 'keyword', 'lists', 'using', 'extensive', 'web', 'crawling', 'identification', 'of', 'metrics', 'to', 'measure', 'the', 'quality', 'of', 'each', 'list', 'yield', 'or', 'coverage', 'volume', 'and', 'keyword', 'average', 'financial', 'value', 'enterprise', 'metadata', 'library', 'with', 'any', 'changes', 'or', 'updates', 'document', 'data', 'quality', 'and', 'traceability', 'documents', 'for', 'each', 'source', 'interface', 'establish', 'standards', 'of', 'procedures', 'generate', 'weekly', 'and', 'monthly', 'asset', 'inventory', 'reports', 'environment', 'erwin', 'r7.0', 'sql', 'server', '2000/2005', 'windows', 'xp/nt/2000', 'oracle', '8i/9i', 'ms-dts', 'uml', 'uat', 'sql', 'loader', 'ood', 'oltp', 'pl/sql', 'ms', 'visio', 'informatica'], ['description', 'fis', 'provides', 'financial', 'software', 'world-class', 'services', 'and', 'global', 'business', 'solutions', 'let', 'us', 'help', 'you', 'compete', 'and', 'win', 'in', 'today', 'chaotic', 'marketplace', 'fidelity', 'national', 'information', 'services', 'inc', 'better', 'known', 'by', 'the', 'abbreviation', 'fis', 'is', 'an', 'international', 'provider', 'of', 'financial', 'services', 'technology', 'and', 'outsourcing', 'services', 'fis', 'is', 'the', 'world', 'largest', 'global', 'provider', 'dedicated', 'to', 'financial', 'technology', 'solutions', 'fis', 'empowers', 'the', 'financial', 'world', 'with', 'software', 'services', 'consulting', 'and', 'outsourcing', 'solutions', 'focused', 'on', 'retail', 'and', 'institutional', 'banking', 'payments', 'asset', 'and', 'wealth', 'management', 'risk', 'and', 'compliance', 'trade', 'enablement', 'transaction', 'processing', 'and', 'record-keeping', 'responsibilities', 'extracted', 'data', 'from', 'hdfs', 'and', 'prepared', 'data', 'for', 'exploratory', 'analysis', 'using', 'data', 'munging', 'built', 'models', 'using', 'statistical', 'techniques', 'like', 'bayesian', 'hmm', 'and', 'machine', 'learning', 'classification', 'models', 'like', 'xgboost', 'svm', 'and', 'random', 'forest', 'participated', 'in', 'all', 'phases', 'of', 'data', 'mining', 'data', 'cleaning', 'data', 'collection', 'developing', 'models', 'validation', 'visualization', 'and', 'performed', 'gap', 'analysis', 'highly', 'immersive', 'data', 'science', 'program', 'involving', 'data', 'manipulation', 'visualization', 'web', 'scraping', 'machine', 'learning', 'python', 'programming', 'sql', 'git', 'mongodb', 'hadoop', 'setup', 'storage', 'and', 'data', 'analysis', 'tools', 'in', 'aws', 'cloud', 'computing', 'infrastructure', 'installed', 'and', 'used', 'caffe', 'deep', 'learning', 'framework', 'worked', 'on', 'different', 'data', 'formats', 'such', 'as', 'json', 'xml', 'and', 'performed', 'machine', 'learning', 'algorithms', 'in', 'python', 'worked', 'as', 'data', 'architects', 'and', 'it', 'architects', 'to', 'understand', 'the', 'movement', 'of', 'data', 'and', 'its', 'storage', 'and', 'er', 'studio', '9.7', 'used', 'pandas', 'numpy', 'seaborn', 'matplotlib', 'scikit-learn', 'scipy', 'nltk', 'in', 'python', 'for', 'developing', 'various', 'machine', 'learning', 'algorithms', 'data', 'manipulation', 'and', 'aggregation', 'from', 'different', 'source', 'using', 'nexus', 'business', 'objects', 'toad', 'power', 'bi', 'and', 'smart', 'view', 'implemented', 'agile', 'methodology', 'for', 'building', 'an', 'internal', 'application', 'focus', 'on', 'integration', 'overlap', 'and', 'informatica', 'newer', 'commitment', 'to', 'mdm', 'with', 'the', 'acquisition', 'of', 'identity', 'systems', 'coded', 'proprietary', 'packages', 'to', 'analyze', 'and', 'visualize', 'spcfile', 'data', 'to', 'identify', 'bad', 'spectra', 'and', 'samples', 'to', 'reduce', 'unnecessary', 'procedures', 'and', 'costs', 'programmed', 'utility', 'in', 'python', 'that', 'used', 'multiple', 'packages', 'numpy', 'scipy', 'pandas', 'implemented', 'classification', 'using', 'supervised', 'algorithms', 'like', 'logistic', 'regression', 'decision', 'trees', 'naive', 'bayes', 'knn', 'as', 'architect', 'delivered', 'various', 'complex', 'olapdatabases/cubes', 'scorecards', 'dashboards', 'and', 'reports', 'updated', 'python', 'scripts', 'to', 'match', 'training', 'data', 'with', 'our', 'database', 'stored', 'in', 'aws', 'cloud', 'search', 'so', 'that', 'we', 'would', 'be', 'able', 'to', 'assign', 'each', 'document', 'response', 'label', 'for', 'further', 'classification', 'used', 'teradata', 'utilities', 'such', 'as', 'fast', 'export', 'mload', 'for', 'handling', 'various', 'tasks', 'data', 'migration/etl', 'from', 'oltp', 'source', 'systems', 'to', 'olap', 'target', 'systems', 'data', 'transformation', 'from', 'various', 'resources', 'data', 'organization', 'features', 'extraction', 'from', 'raw', 'and', 'stored', 'validated', 'the', 'machine', 'learning', 'classifiers', 'using', 'roc', 'curves', 'and', 'lift', 'charts', 'environment', 'unix', 'python', '3.5.2', 'mllib', 'sas', 'regression', 'logistic', 'regression', 'hadoop', '2.7.4', 'nosql', 'teradata', 'oltp', 'random', 'forest', 'olap', 'hdfs', 'ods', 'nltk', 'svm', 'json', 'xml', 'and', 'mapreduce', 'description', 'cbre', 'group', 'inc', 'is', 'the', 'largest', 'commercial', 'real', 'estate', 'services', 'and', 'investment', 'firm', 'in', 'the', 'world', 'it', 'is', 'based', 'in', 'los', 'angeles', 'california', 'and', 'operates', 'more', 'than', '450', 'offices', 'worldwide', 'and', 'has', 'clients', 'in', 'more', 'than', '100', 'countries', 'responsibilities', 'utilized', 'spark', 'scala', 'hadoop', 'hql', 'vql', 'oozie', 'pyspark', 'data', 'lake', 'tensorflow', 'hbase', 'cassandra', 'redshift', 'mongodb', 'kafka', 'kinesis', 'spark', 'streaming', 'edward', 'cuda', 'mllib', 'aws', 'python', 'broad', 'variety', 'of', 'machine', 'learning', 'methods', 'including', 'classifications', 'regressions', 'dimensionally', 'reduction', 'etc', 'utilized', 'the', 'engine', 'to', 'increase', 'user', 'lifetime', 'by', '45', 'and', 'triple', 'user', 'conversations', 'for', 'target', 'categories', 'application', 'of', 'various', 'machine', 'learning', 'algorithms', 'and', 'statistical', 'modeling', 'like', 'decision', 'trees', 'text', 'analytics', 'natural', 'language', 'processing', 'nlp', 'supervised', 'and', 'unsupervised', 'regression', 'models', 'social', 'network', 'analysis', 'neural', 'networks', 'deep', 'learning', 'svm', 'clustering', 'to', 'identify', 'volume', 'using', 'scikit-learn', 'package', 'in', 'python', 'matlab', 'worked', 'onanalyzing', 'data', 'from', 'google', 'analytics', 'adwords', 'facebook', 'etc', 'evaluated', 'models', 'using', 'cross', 'validation', 'log', 'loss', 'function', 'roc', 'curves', 'and', 'used', 'auc', 'for', 'feature', 'selection', 'and', 'elastic', 'technologies', 'like', 'elasticsearch', 'kibana', 'performed', 'data', 'profiling', 'to', 'learn', 'about', 'behavior', 'with', 'various', 'features', 'such', 'as', 'traffic', 'pattern', 'location', 'date', 'and', 'time', 'etc', 'categorized', 'comments', 'into', 'positive', 'and', 'negative', 'clusters', 'from', 'different', 'social', 'networking', 'sites', 'using', 'sentiment', 'analysis', 'and', 'text', 'analytics', 'performed', 'multinomial', 'logistic', 'regression', 'decision', 'tree', 'random', 'forest', 'svm', 'to', 'classify', 'package', 'is', 'going', 'to', 'deliver', 'on', 'time', 'for', 'the', 'new', 'route', 'performed', 'data', 'analysis', 'by', 'using', 'hive', 'to', 'retrieve', 'the', 'data', 'from', 'hadoop', 'cluster', 'sql', 'to', 'retrieve', 'datafrom', 'oracle', 'database', 'and', 'used', 'etl', 'for', 'data', 'transformation', 'performed', 'data', 'cleaning', 'features', 'scaling', 'features', 'engineering', 'using', 'pandas', 'and', 'numpy', 'packages', 'in', 'python', 'exploring', 'dag', 'their', 'dependencies', 'and', 'logs', 'using', 'airflow', 'pipelines', 'for', 'automation', 'performed', 'data', 'cleaning', 'and', 'feature', 'selection', 'using', 'mllib', 'package', 'in', 'pyspark', 'and', 'working', 'with', 'deep', 'learning', 'frameworks', 'such', 'as', 'caffe', 'neon', 'developed', 'spark/scala', 'python', 'for', 'regular', 'expression', 'regex', 'project', 'in', 'the', 'hadoop/hive', 'environment', 'with', 'linux/windows', 'for', 'big', 'data', 'resources', 'used', 'clustering', 'technique', 'k-means', 'to', 'identify', 'outliers', 'and', 'to', 'classify', 'unlabeled', 'data', 'tracking', 'operations', 'using', 'sensors', 'until', 'certain', 'criteria', 'is', 'met', 'using', 'airflowtechnology', 'responsible', 'for', 'different', 'data', 'mapping', 'activities', 'from', 'source', 'systems', 'to', 'teradata', 'using', 'utilities', 'like', 'tpump', 'fexp', 'bteq', 'mload', 'floadetc', 'analyze', 'traffic', 'patterns', 'by', 'calculating', 'autocorrelation', 'with', 'different', 'time', 'lags', 'ensured', 'that', 'the', 'model', 'has', 'low', 'false', 'positive', 'rate', 'and', 'text', 'classification', 'and', 'sentiment', 'analysis', 'for', 'unstructured', 'and', 'semi-structured', 'data', 'addressed', 'over', 'fitting', 'by', 'implementing', 'of', 'the', 'algorithm', 'regularization', 'methods', 'like', 'l1', 'and', 'l2', 'used', 'principal', 'component', 'analysis', 'in', 'feature', 'engineering', 'to', 'analyze', 'high', 'dimensional', 'data', 'used', 'mllib', 'spark', 'machine', 'learning', 'library', 'to', 'build', 'and', 'evaluate', 'different', 'models', 'implemented', 'rule', 'based', 'expertise', 'system', 'from', 'the', 'results', 'of', 'exploratory', 'analysis', 'and', 'information', 'gathered', 'from', 'the', 'people', 'from', 'different', 'departments', 'created', 'and', 'designed', 'reports', 'that', 'will', 'use', 'gathered', 'metrics', 'to', 'infer', 'and', 'draw', 'logical', 'conclusions', 'of', 'past', 'and', 'future', 'behavior', 'developed', 'mapreduce', 'pipeline', 'for', 'feature', 'extraction', 'using', 'hive', 'and', 'pig', 'created', 'data', 'quality', 'scripts', 'using', 'sql', 'and', 'hive', 'to', 'validate', 'successful', 'data', 'load', 'and', 'quality', 'of', 'the', 'data', 'created', 'various', 'types', 'of', 'data', 'visualizations', 'using', 'python', 'and', 'tableau', 'communicated', 'the', 'results', 'with', 'operations', 'team', 'for', 'taking', 'best', 'decisions', 'collected', 'data', 'needs', 'and', 'requirements', 'by', 'interacting', 'with', 'the', 'other', 'departments', 'environment', 'python', '2.x', 'cdh5', 'hdfs', 'hadoop', '2.3', 'hive', 'impala', 'aws', 'linux', 'spark', 'tableau', 'desktop', 'sql', 'server', '2014', 'microsoft', 'excel', 'matlab', 'spark', 'sql', 'pyspark', 'description', 'the', 'walgreens', 'companyis', 'an', 'american', 'company', 'that', 'operatesas', 'the', 'second-largest', 'pharmacy', 'store', 'chain', 'in', 'the', 'united', 'states', 'it', 'specializes', 'in', 'filling', 'prescriptions', 'health', 'and', 'wellness', 'products', 'health', 'information', 'and', 'photo', 'services', 'responsibilities', 'worked', 'with', 'bi', 'team', 'in', 'gathering', 'the', 'report', 'requirements', 'and', 'also', 'sqoop', 'to', 'export', 'data', 'into', 'hdfs', 'and', 'hive', 'involved', 'in', 'the', 'below', 'phases', 'of', 'analytics', 'using', 'python', 'and', 'jupyter', 'notebook', 'data', 'collection', 'and', 'treatment', 'analysed', 'existing', 'internal', 'data', 'and', 'external', 'data', 'worked', 'on', 'entry', 'errors', 'classification', 'errors', 'and', 'defined', 'criteria', 'for', 'missing', 'values', 'data', 'mining', 'used', 'cluster', 'analysis', 'for', 'identifying', 'customer', 'segments', 'decision', 'trees', 'used', 'for', 'profitable', 'and', 'non-profitable', 'customers', 'market', 'basket', 'analysis', 'used', 'for', 'customer', 'purchasing', 'behaviour', 'and', 'part/product', 'association', 'developed', 'multiple', 'map', 'reduce', 'jobs', 'in', 'java', 'for', 'data', 'cleaning', 'and', 'preprocessing', 'assisted', 'with', 'data', 'capacity', 'planning', 'and', 'node', 'forecasting', 'installed', 'configured', 'and', 'managed', 'flume', 'infrastructure', 'administrator', 'for', 'pig', 'hive', 'and', 'hbase', 'installing', 'updates', 'patches', 'and', 'upgrades', 'worked', 'closely', 'with', 'the', 'claims', 'processing', 'team', 'to', 'obtain', 'patterns', 'in', 'filing', 'of', 'fraudulent', 'claims', 'worked', 'on', 'performing', 'major', 'upgrade', 'of', 'cluster', 'from', 'cdh3u6', 'to', 'cdh4.4.0', 'developed', 'map', 'reduce', 'programs', 'to', 'extract', 'and', 'transform', 'the', 'data', 'sets', 'and', 'results', 'were', 'exported', 'back', 'to', 'rdbms', 'using', 'sqoop', 'patterns', 'were', 'observed', 'in', 'fraudulent', 'claims', 'using', 'text', 'mining', 'in', 'and', 'hive', 'exported', 'the', 'data', 'required', 'information', 'to', 'rdbms', 'using', 'sqoop', 'to', 'make', 'the', 'data', 'available', 'for', 'the', 'claims', 'processing', 'team', 'to', 'assist', 'in', 'processing', 'claim', 'based', 'on', 'the', 'data', 'developed', 'map', 'reduce', 'programs', 'to', 'parse', 'the', 'raw', 'data', 'populate', 'staging', 'tables', 'and', 'store', 'the', 'refined', 'data', 'in', 'partitioned', 'tables', 'in', 'the', 'edw', 'created', 'tables', 'in', 'hive', 'and', 'loaded', 'the', 'structured', 'resulted', 'from', 'map', 'reduce', 'jobs', 'data', 'using', 'hiveql', 'developed', 'many', 'queries', 'and', 'extracted', 'the', 'required', 'information', 'created', 'hive', 'queries', 'that', 'helped', 'market', 'analysts', 'spot', 'emerging', 'trends', 'by', 'comparing', 'fresh', 'data', 'with', 'edw', 'reference', 'tables', 'and', 'historical', 'metrics', 'was', 'responsible', 'for', 'importing', 'the', 'data', 'mostly', 'log', 'files', 'from', 'various', 'sources', 'into', 'hdfs', 'using', 'flume', 'enabled', 'speedy', 'reviews', 'and', 'first', 'mover', 'advantages', 'by', 'using', 'oozie', 'to', 'automate', 'data', 'loading', 'into', 'the', 'hadoop', 'distributed', 'file', 'system', 'and', 'pig', 'to', 'pre-process', 'the', 'data', 'provided', 'design', 'recommendations', 'and', 'thought', 'leadership', 'to', 'sponsors/stakeholders', 'that', 'improved', 'review', 'processes', 'and', 'resolved', 'technical', 'problems', 'managed', 'and', 'reviewed', 'hadoop', 'log', 'files', 'tested', 'raw', 'data', 'and', 'executed', 'performance', 'scripts', 'environment', 'hdfs', 'pig', 'hive', 'map', 'reduce', 'linux', 'hbase', 'flume', 'sqoop', 'vmware', 'eclipse', 'cloudera', 'python', 'description', 'transamerica', 'is', 'the', 'us-based', 'brand', 'of', 'aegon', 'dutch', 'financial', 'services', 'firm', 'aegon', 'is', 'one', 'of', 'the', 'world', 'leading', 'providers', 'of', 'life', 'insurance', 'pensions', 'and', 'asset', 'management', 'and', 'is', 'helping', 'approximately', '30', 'million', 'customers', 'globally', 'to', 'achieve', 'lifetime', 'of', 'financial', 'security', 'responsibilities', 'manipulating', 'cleansing', 'processing', 'data', 'using', 'excel', 'access', 'and', 'sql', 'responsible', 'for', 'loading', 'extracting', 'and', 'validation', 'of', 'client', 'data', 'modelled', 'clean', 'data', 'into', 'the', 'kafka', 'servers', 'for', 'use', 'over', 'the', 'spark', 'engine', 'zookeeper', 'along', 'with', 'kafka', 'was', 'used', 'to', 'stream', 'data', 'and', 'end-to-end', 'client', 'communication', 'performed', 'transformations', 'over', 'the', 'warehoused', 'data', 'using', 'scala', 'python', 'and', 'modelled', 'the', 'data', 'back', 'into', 'the', 'servers', 'for', 'iterative', 'transformations', 'into', 'kafka', 'modelled', 'data', 'using', 'machine', 'learning', 'libraries', 'sci-kit', 'learn', 'apart', 'from', 'svn', 'and', 'knn', 'based', 'classificationto', 'create', 'training', 'dataset', 'for', 'use', 'in', 'predictive', 'model', 'liaising', 'with', 'end-users', 'and', '3rd', 'party', 'suppliers', 'analyzing', 'raw', 'data', 'drawing', 'conclusions', 'developing', 'recommendations', 'writing', 't-sql', 'scripts', 'to', 'manipulate', 'data', 'for', 'data', 'loads', 'and', 'extracts', 'developing', 'data', 'analytical', 'databases', 'from', 'complex', 'financial', 'source', 'data', 'performing', 'daily', 'system', 'checks', 'data', 'entry', 'data', 'auditing', 'creating', 'data', 'reports', 'monitoring', 'all', 'data', 'for', 'accuracy', 'designing', 'developing', 'and', 'implementing', 'new', 'functionality', 'monitoring', 'the', 'automated', 'loading', 'processes', 'advising', 'on', 'the', 'suitability', 'of', 'methodologies', 'and', 'suggesting', 'improvements', 'carrying', 'out', 'specified', 'data', 'processing', 'and', 'statistical', 'techniques', 'supplying', 'qualitative', 'and', 'quantitative', 'data', 'to', 'colleagues', 'clients', 'using', 'informatica', 'sas', 'to', 'extract', 'transform', 'load', 'source', 'data', 'from', 'transaction', 'systems', 'performed', 'sequential', 'analytics', 'using', 'sas', 'enterprise', 'miner', 'using', 'jobs', 'fed', 'by', 'the', 'sas', 'grid', 'manager', 'loaded', 'packages', 'and', 'stored', 'procedures', 'using', 'base', 'sas', 'and', 'integrated', 'functional', 'and', 'business', 'requirements', 'using', 'the', 'ebi', 'suite', 'creating', 'data', 'pipelines', 'using', 'big', 'data', 'technologies', 'like', 'hadoop', 'spark', 'etc', 'creating', 'statistical', 'models', 'using', 'distributed', 'and', 'standalone', 'models', 'to', 'build', 'various', 'diagnostics', 'predictive', 'and', 'prescriptive', 'solution', 'utilize', 'broad', 'variety', 'of', 'statistical', 'packages', 'like', 'sas', 'mlib', 'graphs', 'hadoop', 'spark', 'mapreduce', 'pig', 'performed', 'check', 'using', 'quality', 'parameters', 'fed', 'using', 'the', 'sas', 'qc', 'engine', 'created', 'ui', 'dashboard', 'for', 'end', 'users', 'and', 'performed', 'prototype', 'testing', 'using', 'tableau', 'refine', 'and', 'train', 'models', 'based', 'on', 'domain', 'knowledge', 'and', 'customer', 'business', 'objectives', 'deliver', 'or', 'collaborate', 'on', 'delivering', 'effective', 'visualizations', 'to', 'support', 'the', 'client', 'business', 'objectives', 'communicate', 'to', 'your', 'peers', 'and', 'managers', 'promptly', 'as', 'and', 'when', 'required', 'produce', 'solid', 'and', 'effective', 'strategies', 'based', 'on', 'accurate', 'and', 'meaningful', 'data', 'reports', 'and', 'analysis', 'and/or', 'keen', 'observations', 'establish', 'and', 'maintain', 'communication', 'with', 'clients', 'and/or', 'team', 'members', 'understand', 'needs', 'resolve', 'issues', 'and', 'meet', 'expectations', 'developed', 'web', 'applications', 'using', 'net', 'technologies', 'work', 'on', 'bug', 'fixes/issues', 'that', 'arise', 'in', 'the', 'production', 'environment', 'and', 'resolve', 'them', 'at', 'the', 'earliest', 'environment', 'cloudera', 'hdfs', 'pig', 'hive', 'map', 'reduce', 'python', 'sqoop', 'storm', 'kafka', 'linux', 'hbase', 'impala', 'java', 'sql', 'cassandra', 'mongodb', 'svn', 'description', 'infotech', 'enterprises', 'it', 'services', 'pvt', 'ltd', 'infotech', 'it', 'part', 'of', 'the', '260', 'million', 'infotech', 'enterprises', 'group', 'leverages', 'its', 'business', 'process', 'knowledge', 'technological', 'competence', 'strategic', 'alliances', 'and', 'strong', 'global', 'presence', 'to', 'offer', 'innovative', 'it', 'solutions', 'to', 'the', 'retail', 'industry', 'responsibilities', 'worked', 'with', 'large', 'amounts', 'of', 'structured', 'and', 'unstructured', 'data', 'knowledge', 'in', 'machine', 'learning', 'concepts', 'generalized', 'linear', 'models', 'regularization', 'random', 'forest', 'time', 'series', 'models', 'etc', 'worked', 'in', 'business', 'intelligence', 'tools', 'and', 'visualization', 'tools', 'such', 'as', 'business', 'objects', 'tableau', 'chartio', 'etc', 'deployed', 'gui', 'pages', 'by', 'using', 'jsp', 'jstl', 'html', 'dhtml', 'xhtml', 'css', 'javascript', 'ajax', 'configured', 'the', 'project', 'on', 'websphere', '6.1', 'application', 'servers', 'implemented', 'the', 'online', 'application', 'by', 'using', 'core', 'java', 'jdbc', 'jsp', 'servlets', 'and', 'ejb', '1.1', 'web', 'services', 'soap', 'wsdl', 'handled', 'end-to-end', 'project', 'from', 'data', 'discovery', 'to', 'model', 'deployment', 'monitoring', 'the', 'automated', 'loading', 'processes', 'communicated', 'with', 'other', 'health', 'care', 'info', 'by', 'using', 'web', 'services', 'with', 'the', 'help', 'of', 'soap', 'wsdljax-rpc', 'used', 'singleton', 'factory', 'design', 'pattern', 'dao', 'design', 'patterns', 'based', 'on', 'the', 'application', 'requirements', 'used', 'sax', 'and', 'dom', 'parsers', 'to', 'parse', 'the', 'raw', 'xml', 'documents', 'used', 'rad', 'as', 'development', 'ide', 'for', 'web', 'applications', 'preparing', 'and', 'executing', 'unit', 'test', 'cases', 'used', 'log4j', 'logging', 'framework', 'to', 'write', 'log', 'messages', 'with', 'various', 'levels', 'involved', 'in', 'fixing', 'bugs', 'and', 'minor', 'enhancements', 'for', 'the', 'front-end', 'modules', 'implemented', 'microsoft', 'visio', 'and', 'rational', 'rose', 'for', 'designing', 'the', 'use', 'case', 'diagrams', 'class', 'model', 'sequence', 'diagrams', 'and', 'activity', 'diagrams', 'for', 'sdlc', 'process', 'of', 'the', 'application', 'doing', 'functional', 'and', 'technical', 'reviews', 'maintenance', 'in', 'the', 'testing', 'team', 'for', 'system', 'testing/integration/uat', 'guaranteeing', 'quality', 'in', 'the', 'deliverables', 'conducted', 'design', 'reviews', 'and', 'technical', 'reviews', 'with', 'other', 'project', 'stakeholders', 'was', 'part', 'of', 'the', 'complete', 'life', 'cycle', 'of', 'the', 'project', 'from', 'the', 'requirements', 'to', 'the', 'production', 'support', 'created', 'test', 'plan', 'documents', 'for', 'all', 'back-end', 'database', 'modules', 'implemented', 'the', 'project', 'in', 'linux', 'environment', 'environment', '3.0', 'erwin', '9.5', 'tableau', '8.0', 'mdm', 'qlikview', 'mllib', 'pl/sql', 'hdfs', 'teradata', '14.1', 'json', 'hadoop', 'hdfs', 'mapreduce', 'pig', 'spark', 'studio', 'mahout', 'java', 'hive', 'aws', 'description', 'globallogic', 'provides', 'experience', 'design', 'digital', 'product', 'engineering', 'services', 'and', 'agile', 'software', 'development', 'to', 'the', 'world', 'top', 'brands', 'by', 'leveraging', 'ux', 'ui', 'design', 'next-gen', 'technologies', 'and', 'cloud', 'software', 'with', 'end-to-end', 'solution', 'by', 'the', 'best', 'software', 'development', 'company', 'responsibilities', 'developed', 'internet', 'traffic', 'scoring', 'platform', 'for', 'ad', 'networks', 'advertisers', 'and', 'publishers', 'rule', 'engine', 'site', 'scoring', 'keyword', 'scoring', 'lift', 'measurement', 'linkage', 'analysis', 'responsible', 'for', 'defining', 'the', 'key', 'identifiers', 'for', 'each', 'mapping/interface', 'clients', 'include', 'ebay', 'click', 'forensics', 'cars.com', 'turn.com', 'microsoft', 'and', 'looksmart', 'designed', 'the', 'architecture', 'for', 'one', 'of', 'the', 'first', 'analytics', '3.0', 'online', 'platforms', 'all-purpose', 'scoring', 'with', 'on-demand', 'saas', 'api', 'services', 'currently', 'under', 'implementation', 'web', 'crawling', 'and', 'text', 'mining', 'techniques', 'to', 'score', 'referral', 'domains', 'generate', 'keyword', 'taxonomies', 'and', 'assess', 'commercial', 'value', 'of', 'bid', 'keywords', 'developed', 'new', 'hybrid', 'statistical', 'and', 'data', 'mining', 'technique', 'known', 'as', 'hidden', 'decision', 'trees', 'and', 'hidden', 'forests', 'reverse', 'engineering', 'of', 'keyword', 'pricing', 'algorithms', 'in', 'the', 'context', 'of', 'pay-per-click', 'arbitrage', 'implementation', 'of', 'metadata', 'repository', 'maintaining', 'data', 'quality', 'data', 'cleanup', 'procedures', 'transformations', 'data', 'standards', 'data', 'governance', 'program', 'scripts', 'stored', 'procedures', 'triggers', 'and', 'execution', 'of', 'test', 'plans', 'performed', 'data', 'quality', 'in', 'talend', 'open', 'studio', 'coordinated', 'meetings', 'with', 'vendors', 'to', 'define', 'requirements', 'and', 'system', 'interaction', 'agreement', 'documentation', 'between', 'client', 'and', 'vendor', 'system', 'automated', 'bidding', 'for', 'advertiser', 'campaigns', 'based', 'either', 'on', 'keyword', 'or', 'category', 'run-of-site', 'bidding', 'creation', 'of', 'multimillion', 'bid', 'keyword', 'lists', 'using', 'extensive', 'web', 'crawling', 'identification', 'of', 'metrics', 'to', 'measure', 'the', 'quality', 'of', 'each', 'list', 'yield', 'or', 'coverage', 'volume', 'and', 'keyword', 'average', 'financial', 'value', 'enterprise', 'metadata', 'library', 'with', 'any', 'changes', 'or', 'updates', 'document', 'data', 'quality', 'and', 'traceability', 'documents', 'for', 'each', 'source', 'interface', 'establish', 'standards', 'of', 'procedures', 'generate', 'weekly', 'and', 'monthly', 'asset', 'inventory', 'reports', 'environment', 'erwin', 'r7.0', 'sql', 'server', '2000/2005', 'windows', 'xp/nt/2000', 'oracle', '8i/9i', 'ms-dts', 'uml', 'uat', 'sql', 'loader', 'ood', 'oltp', 'pl/sql', 'ms', 'visio', 'informatica'], ['description', 'verizon', 'wireless', 'is', 'an', 'american', 'telecommunications', 'company', 'wholly', 'owned', 'subsidiary', 'of', 'verizon', 'communications', 'which', 'offers', 'wireless', 'products', 'and', 'services', 'verizon', 'wireless', 'is', 'the', 'largest', 'wireless', 'telecommunications', 'provider', 'in', 'the', 'united', 'states', 'the', 'company', 'is', 'headquartered', 'in', 'basking', 'ridge', 'new', 'jersey', 'it', 'was', 'founded', 'in', '2000', 'as', 'joint', 'venture', 'of', 'american', 'telecommunications', 'firm', 'bell', 'atlantic', 'which', 'would', 'soon', 'become', 'verizon', 'communications', 'and', 'british', 'multinational', 'telecommunications', 'company', 'vodafone', 'responsibilities', 'responsible', 'for', 'working', 'with', 'various', 'teams', 'on', 'project', 'to', 'develop', 'analytics', 'based', 'solution', 'to', 'target', 'roaming', 'subscribers', 'specifically', 'leading', 'team', 'of', 'data', 'analysts', 'and', 'created', 'multi-dimensional', 'segmentation', 'to', 'define', 'specific', 'cohorts', 'of', 'subscribers', 'preparing', 'the', 'travel', 'prediction', 'model', 'that', 'can', 'predict', 'subscribers', 'future', 'travel', 'behavior', 'up', 'to', 'month', 'in', 'advance', 'combination', 'of', 'these', 'elements', 'travel', 'prediction', 'multi-dimensional', 'segmentation', 'would', 'enable', 'operators', 'to', 'conduct', 'highly', 'targeted', 'and', 'personalized', 'roaming', 'services', 'campaigns', 'leading', 'to', 'significant', 'subscriber', 'uptake', 'scaled', 'up', 'to', 'machine', 'learning', 'pipelines', '4600', 'processors', '35000', 'gb', 'memory', 'achieving', '5-minute', 'execution', 'deployed', 'gui', 'pages', 'by', 'using', 'jsp', 'jstl', 'html', 'dhtml', 'xhtml', 'css', 'javascript', 'ajax', 'configured', 'the', 'project', 'on', 'websphere', '6.1', 'application', 'servers', 'developed', 'machine', 'learning', 'test-bed', 'with', '24', 'different', 'model', 'learning', 'and', 'feature', 'learning', 'algorithms', 'by', 'thorough', 'systematic', 'search', 'demonstrated', 'performance', 'surpassing', 'the', 'state-of-the-art', 'deep', 'learning', 'up', 'to', '10', 'times', 'more', 'accurate', 'predictions', 'over', 'existing', 'state-of-the-art', 'algorithms', 'developed', 'in-disk', 'huge', '100gb', 'highly', 'complex', 'machine', 'learning', 'models', 'used', 'sax', 'and', 'dom', 'parsers', 'to', 'parse', 'the', 'raw', 'xml', 'documents', 'used', 'rad', 'as', 'development', 'ide', 'for', 'web', 'applications', 'develop', 'and', 'plan', 'required', 'analytic', 'projects', 'in', 'response', 'to', 'business', 'needs', 'in', 'conjunction', 'with', 'data', 'owners', 'and', 'department', 'managers', 'contribute', 'to', 'the', 'development', 'of', 'data', 'models', 'and', 'protocols', 'for', 'mining', 'production', 'databases', 'develop', 'new', 'analytical', 'methods', 'and/or', 'tools', 'as', 'required', 'contribute', 'to', 'data', 'mining', 'architectures', 'modeling', 'standards', 'reporting', 'and', 'data', 'analysis', 'methodologies', 'conduct', 'research', 'and', 'make', 'recommendations', 'on', 'data', 'mining', 'products', 'services', 'protocols', 'and', 'standards', 'in', 'support', 'of', 'procurement', 'and', 'development', 'efforts', 'work', 'with', 'application', 'developers', 'to', 'extract', 'data', 'relevant', 'for', 'analysis', 'collaborate', 'with', 'unit', 'managers', 'end', 'users', 'development', 'staff', 'and', 'other', 'stakeholders', 'to', 'integrate', 'data', 'mining', 'results', 'with', 'existing', 'systems', 'provide', 'and', 'apply', 'quality', 'assurance', 'best', 'practices', 'for', 'data', 'mining/analysis', 'services', 'environment', '9.0', 'informatica', '9.0', 'ods', 'oltp', 'oracle', '10g', 'hive', 'olap', 'db2', 'metadata', 'ms', 'excel', 'mainframes', 'ms', 'vision', 'rational', 'rose', 'description', 'marvell', 'technology', 'group', 'limited', 'is', 'producer', 'of', 'storage', 'communications', 'and', 'consumer', 'semiconductor', 'products', 'marvell', 'u.s', 'operating', 'headquarters', 'is', 'located', 'in', 'santa', 'clara', 'california', 'and', 'the', 'company', 'operates', 'design', 'centers', 'in', 'places', 'including', 'canada', 'europe', 'israel', 'india', 'singapore', 'and', 'china', 'marvell', 'is', 'fabless', 'manufacturer', 'of', 'semiconductors', 'its', 'market', 'segments', 'include', 'the', 'enterprise', 'cloud', 'automotive', 'industrial', 'and', 'consumer', 'markets', 'responsibilities', 'developed', 'the', 'prediction', 'model', 'for', 'crop', 'yield', 'based', 'on', 'different', 'kinds', 'of', 'field', 'weather', 'and', 'imagery', 'data', 'exploratory', 'data', 'analysis', 'and', 'feature', 'engineering', 'to', 'best', 'fit', 'the', 'regression', 'model', 'designed', 'static', 'pipeline', 'in', 'ms', 'azure', 'for', 'data', 'ingestion', 'and', 'dashboarding', 'used', 'ms', 'ml', 'studio', 'for', 'modeling', 'and', 'ms', 'power', 'bi', 'for', 'dash', 'boarding', 'analyze', 'large', 'datasets', 'to', 'provide', 'strategic', 'direction', 'to', 'the', 'company', 'perform', 'quantitative', 'analysis', 'of', 'product', 'sales', 'trends', 'to', 'recommend', 'pricing', 'decisions', 'conduct', 'cost', 'and', 'benefits', 'analysis', 'on', 'new', 'ideas', 'scrutinize', 'and', 'track', 'customer', 'behavior', 'to', 'identify', 'trends', 'and', 'unmet', 'needs', 'develop', 'statistical', 'models', 'to', 'forecast', 'inventory', 'and', 'procurement', 'cycles', 'assist', 'in', 'developing', 'internal', 'tools', 'for', 'data', 'analysis', 'advising', 'on', 'the', 'suitability', 'of', 'methodologies', 'and', 'suggesting', 'improvements', 'carrying', 'out', 'specified', 'data', 'processing', 'and', 'statistical', 'techniques', 'supplying', 'qualitative', 'and', 'quantitative', 'data', 'to', 'colleagues', 'clients', 'using', 'informatica', 'sas', 'to', 'extract', 'transform', 'load', 'source', 'data', 'from', 'transaction', 'systems', 'creating', 'data', 'pipelines', 'using', 'big', 'data', 'technologies', 'like', 'hadoop', 'spark', 'etc', 'creating', 'statistical', 'models', 'using', 'distributed', 'and', 'standalone', 'models', 'to', 'build', 'various', 'diagnostics', 'predictive', 'and', 'prescriptive', 'solution', 'utilize', 'broad', 'variety', 'of', 'statistical', 'packages', 'like', 'sas', 'mlib', 'graphs', 'hadoop', 'spark', 'mapreduce', 'pig', 'and', 'others', 'refine', 'and', 'train', 'models', 'based', 'on', 'domain', 'knowledge', 'and', 'customer', 'business', 'objectives', 'deliver', 'or', 'collaborate', 'on', 'delivering', 'effective', 'visualizations', 'to', 'support', 'the', 'client', 'business', 'objectives', 'communicate', 'to', 'your', 'peers', 'and', 'managers', 'promptly', 'as', 'and', 'when', 'required', 'produce', 'solid', 'and', 'effective', 'strategies', 'based', 'on', 'accurate', 'and', 'meaningful', 'data', 'reports', 'and', 'analysis', 'and/or', 'keen', 'observations', 'establish', 'and', 'maintain', 'communication', 'with', 'clients', 'and/or', 'team', 'members', 'understand', 'needs', 'resolve', 'issues', 'and', 'meet', 'expectations', 'developed', 'web', 'applications', 'using', 'net', 'technologies', 'work', 'on', 'bug', 'fixes/issues', 'that', 'arise', 'in', 'the', 'production', 'environment', 'and', 'resolve', 'them', 'at', 'the', 'earliest', 'environment', 'sql', 'server', '2008r2/2005', 'enterprise', 'ssrs', 'ssis', 'crystal', 'reports', 'hadoop', 'windows', 'enterprise', 'server', '2000', 'dts', 'sql', 'profiler', 'and', 'query', 'analyzer', 'description', 'ebay', 'is', 'multinational', 'e-commerce', 'corporation', 'facilitating', 'online', 'consumer-to', 'consumer', 'and', 'business-to-consumer', 'sales', 'it', 'is', 'headquartered', 'in', 'san', 'jose', 'california', 'ebay', 'was', 'founded', 'by', 'pierre', 'omidyar', 'in', '1995', 'and', 'became', 'notable', 'success', 'story', 'of', 'the', 'dot-com', 'bubble', 'responsibilities', 'developed', 'scalable', 'machine', 'learning', 'solutions', 'within', 'distributed', 'computation', 'framework', 'e.g', 'hadoop', 'spark', 'storm', 'etc', 'utilizing', 'nlp', 'applications', 'such', 'as', 'topic', 'models', 'and', 'sentiment', 'analysis', 'to', 'identify', 'trends', 'and', 'patterns', 'within', 'massive', 'data', 'sets', 'creating', 'automated', 'anomaly', 'detection', 'systems', 'and', 'constant', 'tracking', 'of', 'its', 'performance', 'strong', 'command', 'of', 'data', 'architecture', 'and', 'data', 'modelling', 'techniques', 'knowledge', 'in', 'ml', 'statistical', 'libraries', 'e.g', 'scikit-learn', 'pandas', 'having', 'knowledge', 'to', 'build', 'predict', 'models', 'to', 'forecast', 'risks', 'for', 'product', 'launches', 'and', 'operations', 'and', 'help', 'predict', 'workflow', 'and', 'capacity', 'requirements', 'for', 'trms', 'operations', 'having', 'experience', 'with', 'visualization', 'technologies', 'such', 'as', 'tableau', 'draw', 'inferences', 'and', 'conclusions', 'and', 'create', 'dashboards', 'and', 'visualizations', 'of', 'processed', 'data', 'identify', 'trends', 'anomalies', 'generation', 'of', 'tlfs', 'and', 'summary', 'reports', 'etc', 'ensuring', 'on-time', 'quality', 'delivery', 'participated', 'in', 'client', 'meetings', 'teleconferences', 'and', 'video', 'conferences', 'to', 'keep', 'track', 'of', 'project', 'requirements', 'commitments', 'made', 'and', 'the', 'delivery', 'thereof', 'solved', 'analytical', 'problems', 'and', 'effectively', 'communicate', 'methodologies', 'and', 'results', 'worked', 'closely', 'with', 'internal', 'stakeholders', 'such', 'as', 'business', 'teams', 'product', 'managers', 'engineering', 'teams', 'and', 'partner', 'teams', 'data', 'mining', 'using', 'state-of-the-art', 'methods', 'extending', 'company', 'data', 'with', 'third', 'party', 'sources', 'of', 'information', 'when', 'needed', 'enhancing', 'data', 'collection', 'procedures', 'to', 'include', 'information', 'that', 'is', 'relevant', 'for', 'building', 'analytic', 'systems', 'processing', 'cleansing', 'and', 'verifying', 'the', 'integrity', 'of', 'data', 'used', 'for', 'analysis', 'doing', 'ad-hoc', 'analysis', 'and', 'presenting', 'results', 'in', 'clear', 'manner', 'created', 'automated', 'metrics', 'using', 'complex', 'databases', 'foster', 'culture', 'of', 'continuous', 'engineering', 'improvement', 'through', 'mentoring', 'feedback', 'and', 'metrics', 'environment', 'erwin', 'r9.0', 'informatica', '9.0', 'ods', 'oltp', 'oracle', '10g', 'hive', 'olap', 'db2', 'metadata', 'ms', 'excel', 'mainframes', 'ms', 'visio', 'rational', 'rose', 'requisite', 'pro', 'hadoop', 'pl/sql', 'etc', 'description', 'eagle', 'trading', 'systems', 'inc', 'is', 'financial', 'investment', 'advisory', 'firm', 'headquartered', 'in', 'princeton', 'new', 'jersey', 'the', 'firm', 'manages', 'accounts', 'totaling', 'an', 'estimated', '481', 'million', 'of', 'assets', 'under', 'management', 'responsibilities', 'worked', 'with', 'ajax', 'api', 'calls', 'to', 'communicate', 'with', 'hadoop', 'through', 'impala', 'connection', 'and', 'sql', 'to', 'render', 'the', 'required', 'data', 'through', 'it', 'these', 'api', 'calls', 'are', 'similar', 'to', 'microsoft', 'cognitive', 'api', 'calls', 'good', 'grip', 'on', 'cloudera', 'and', 'hdp', 'ecosystem', 'components', 'used', 'elasticsearch', 'big', 'data', 'to', 'retrieve', 'data', 'into', 'application', 'as', 'required', 'performed', 'map', 'reduce', 'programs', 'those', 'are', 'running', 'on', 'the', 'cluster', 'developed', 'multiple', 'mapreduce', 'jobs', 'in', 'java', 'for', 'data', 'cleaning', 'and', 'preprocessing', 'statistical', 'modelling', 'with', 'ml', 'to', 'bring', 'insights', 'in', 'data', 'under', 'guidance', 'of', 'principal', 'data', 'scientist', 'data', 'modeling', 'with', 'pig', 'hive', 'impala', 'ingestion', 'with', 'sqoop', 'flume', 'used', 'svn', 'to', 'commit', 'the', 'changes', 'into', 'the', 'main', 'emm', 'application', 'trunk', 'understanding', 'and', 'implementation', 'of', 'text', 'mining', 'concepts', 'graph', 'processing', 'and', 'semi', 'structured', 'and', 'unstructured', 'data', 'processing', 'analyzed', 'the', 'partitioned', 'and', 'bucketed', 'data', 'and', 'compute', 'various', 'metrics', 'for', 'reporting', 'involved', 'in', 'loading', 'data', 'from', 'rdbms', 'and', 'web', 'logs', 'into', 'hdfs', 'using', 'sqoop', 'and', 'flume', 'worked', 'on', 'loading', 'the', 'data', 'from', 'mysql', 'to', 'hbase', 'where', 'necessary', 'using', 'sqoop', 'developed', 'hive', 'queries', 'for', 'analysis', 'across', 'different', 'banners', 'extracted', 'data', 'from', 'twitter', 'using', 'java', 'and', 'twitter', 'api', 'parsed', 'json', 'formatted', 'twitter', 'data', 'and', 'uploaded', 'to', 'database', 'launching', 'amazon', 'ec2', 'cloud', 'instances', 'using', 'amazon', 'images', 'linux', 'ubuntu', 'and', 'configuring', 'launched', 'instances', 'with', 'respect', 'to', 'specific', 'applications', 'exported', 'the', 'result', 'set', 'from', 'hive', 'to', 'mysql', 'using', 'sqoop', 'after', 'processing', 'the', 'data', 'analyzed', 'the', 'data', 'by', 'performing', 'hive', 'queries', 'and', 'running', 'pig', 'scripts', 'to', 'study', 'customer', 'behavior', 'have', 'hands', 'on', 'experience', 'working', 'on', 'sequence', 'files', 'avro', 'har', 'file', 'formats', 'and', 'compression', 'used', 'hive', 'to', 'partition', 'and', 'bucket', 'data', 'experience', 'in', 'writing', 'mapreduce', 'programs', 'with', 'java', 'api', 'to', 'cleanse', 'structured', 'and', 'unstructured', 'data', 'wrote', 'pig', 'scripts', 'to', 'perform', 'etl', 'procedures', 'on', 'the', 'data', 'in', 'hdfs', 'created', 'hbase', 'tables', 'to', 'store', 'various', 'data', 'formats', 'of', 'data', 'coming', 'from', 'different', 'portfolios', 'worked', 'on', 'improving', 'performance', 'of', 'existing', 'pig', 'and', 'hive', 'queries', 'environment', 'sql/server', 'oracle', '9i', 'ms-office', 'teradata', 'informatica', 'er', 'studio', 'xml', 'business', 'objects', 'hdfs', 'teradata', '14.1', 'json', 'hadoop', 'hdfs', 'mapreduce', 'pig', 'spark', 'studio', 'mahout', 'java', 'hive', 'aws', 'description', 'first', 'indian', 'corporation', 'private', 'limited', 'member', 'of', 'the', 'first', 'american', 'family', 'of', 'companies', 'provides', 'specialized', 'offshore', 'transaction', 'services', 'technology', 'services', 'and', 'analytics', 'to', 'the', 'mortgage', 'industry', 'responsibilities', 'worked', 'with', 'large', 'amounts', 'of', 'structured', 'and', 'unstructured', 'data', 'knowledge', 'in', 'machine', 'learning', 'concepts', 'generalized', 'linear', 'models', 'regularization', 'random', 'forest', 'time', 'series', 'models', 'etc', 'worked', 'in', 'business', 'intelligence', 'tools', 'and', 'visualization', 'tools', 'such', 'as', 'business', 'objects', 'tableau', 'chartio', 'etc', 'deployed', 'gui', 'pages', 'by', 'using', 'jsp', 'jstl', 'html', 'dhtml', 'xhtml', 'css', 'javascript', 'ajax', 'configured', 'the', 'project', 'on', 'websphere', '6.1', 'application', 'servers', 'implemented', 'the', 'online', 'application', 'by', 'using', 'core', 'java', 'jdbc', 'jsp', 'servlets', 'and', 'ejb', '1.1', 'web', 'services', 'soap', 'wsdl', 'handled', 'end-to-end', 'project', 'from', 'data', 'discovery', 'to', 'model', 'deployment', 'monitoring', 'the', 'automated', 'loading', 'processes', 'communicated', 'with', 'other', 'health', 'care', 'info', 'by', 'using', 'web', 'services', 'with', 'the', 'help', 'of', 'soap', 'wsdl', 'jax-rpc', 'used', 'singleton', 'factory', 'design', 'pattern', 'dao', 'design', 'patterns', 'based', 'on', 'the', 'application', 'requirements', 'used', 'sax', 'and', 'dom', 'parsers', 'to', 'parse', 'the', 'raw', 'xml', 'documents', 'used', 'rad', 'as', 'development', 'ide', 'for', 'web', 'applications', 'preparing', 'and', 'executing', 'unit', 'test', 'cases', 'used', 'log4j', 'logging', 'framework', 'to', 'write', 'log', 'messages', 'with', 'various', 'levels', 'involved', 'in', 'fixing', 'bugs', 'and', 'minor', 'enhancements', 'for', 'the', 'front-end', 'modules', 'implemented', 'microsoft', 'visio', 'and', 'rational', 'rose', 'for', 'designing', 'the', 'use', 'case', 'diagrams', 'class', 'model', 'sequence', 'diagrams', 'and', 'activity', 'diagrams', 'for', 'sdlc', 'process', 'of', 'the', 'application', 'doing', 'functional', 'and', 'technical', 'reviews', 'maintenance', 'in', 'the', 'testing', 'team', 'for', 'system', 'testing/integration/uat', 'guaranteeing', 'quality', 'in', 'the', 'deliverables', 'conducted', 'design', 'reviews', 'and', 'technical', 'reviews', 'with', 'other', 'project', 'stakeholders', 'was', 'part', 'of', 'the', 'complete', 'life', 'cycle', 'of', 'the', 'project', 'from', 'the', 'requirements', 'to', 'the', 'production', 'support', 'environment', '3.0', 'erwin', '9.5', 'tableau', '8.0', 'mdm', 'qlikview', 'mllib', 'pl/sql', 'hdfs', 'teradata', '14.1', 'json', 'hadoop', 'hdfs', 'mapreduce', 'pig', 'spark', 'studio', 'mahout', 'java', 'hive', 'aws', 'description', 'accenture', 'plc', 'is', 'global', 'management', 'consulting', 'and', 'professional', 'services', 'company', 'that', 'provides', 'strategy', 'consulting', 'digital', 'technology', 'and', 'operations', 'responsibilities', 'developed', 'internet', 'traffic', 'scoring', 'platform', 'for', 'ad', 'networks', 'advertisers', 'and', 'publishers', 'rule', 'engine', 'site', 'scoring', 'keyword', 'scoring', 'lift', 'measurement', 'linkage', 'analysis', 'responsible', 'for', 'defining', 'the', 'key', 'identifiers', 'for', 'each', 'mapping/interface', 'clients', 'include', 'ebay', 'click', 'forensics', 'cars.com', 'turn.com', 'microsoft', 'and', 'looksmart', 'designed', 'the', 'architecture', 'for', 'one', 'of', 'the', 'first', 'analytics', '3.0', 'online', 'platforms', 'all-purpose', 'scoring', 'with', 'on-demand', 'saas', 'api', 'services', 'currently', 'under', 'implementation', 'web', 'crawling', 'and', 'text', 'mining', 'techniques', 'to', 'score', 'referral', 'domains', 'generate', 'keyword', 'taxonomies', 'and', 'assess', 'commercial', 'value', 'of', 'bid', 'keywords', 'developed', 'new', 'hybrid', 'statistical', 'and', 'data', 'mining', 'technique', 'known', 'as', 'hidden', 'decision', 'trees', 'and', 'hidden', 'forests', 'reverse', 'engineering', 'of', 'keyword', 'pricing', 'algorithms', 'in', 'the', 'context', 'of', 'pay-per-click', 'arbitrage', 'implementation', 'of', 'metadata', 'repository', 'maintaining', 'data', 'quality', 'data', 'cleanup', 'procedures', 'transformations', 'data', 'standards', 'data', 'governance', 'program', 'scripts', 'stored', 'procedures', 'triggers', 'and', 'execution', 'of', 'test', 'plans', 'performed', 'data', 'quality', 'in', 'talend', 'open', 'studio', 'coordinated', 'meetings', 'with', 'vendors', 'to', 'define', 'requirements', 'and', 'system', 'interaction', 'agreement', 'documentation', 'between', 'client', 'and', 'vendor', 'system', 'automated', 'bidding', 'for', 'advertiser', 'campaigns', 'based', 'either', 'on', 'keyword', 'or', 'category', 'run-of-site', 'bidding', 'creation', 'of', 'multimillion', 'bid', 'keyword', 'lists', 'using', 'extensive', 'web', 'crawling', 'identification', 'of', 'metrics', 'to', 'measure', 'the', 'quality', 'of', 'each', 'list', 'yield', 'or', 'coverage', 'volume', 'and', 'keyword', 'average', 'financial', 'value', 'enterprise', 'metadata', 'library', 'with', 'any', 'changes', 'or', 'updates', 'document', 'data', 'quality', 'and', 'traceability', 'documents', 'for', 'each', 'source', 'interface', 'establish', 'standards', 'of', 'procedures', 'generate', 'weekly', 'and', 'monthly', 'asset', 'inventory', 'reports', 'environment', 'erwin', 'r7.0', 'sql', 'server', '2000/2005', 'windows', 'xp/nt/2000', 'oracle', '8i/9i', 'ms-dts', 'uml', 'uat', 'sql', 'loader', 'ood', 'oltp', 'pl/sql', 'ms', 'visio', 'informatica'], ['created', 'sql', 'tables', 'with', 'referential', 'integrity', 'and', 'developed', 'queries', 'using', 'sql', 'plsql', 'and', 'sql*plus', 'performed', 'data', 'integrity', 'checks', 'data', 'cleaning', 'exploratory', 'analysis', 'and', 'feature', 'engineer', 'using', '3.4.0', 'conducted', 'analysis', 'of', 'assessing', 'consumer', 'behaviour', 'and', 'discover', 'the', 'value', 'of', 'customers', 'with', 'rmf', 'analysis', 'applied', 'customer', 'segmentation', 'with', 'clustering', 'algorithms', 'such', 'as', 'k-means', 'clustering', 'and', 'hierarchical', 'clustering', 'developed', 'personalized', 'products', 'recommendation', 'with', 'machine', 'learning', 'algorithms', 'including', 'collaborative', 'filtering', 'and', 'gradient', 'boosting', 'tree', 'to', 'better', 'meet', 'the', 'needs', 'of', 'existing', 'customers', 'and', 'acquire', 'new', 'customers', 'used', 'python', '3.x', 'numpy', 'scipy', 'pandas', 'scikit-learn', 'seaborn', 'nltk', 'and', 'spark', '1.6', '2.0', 'pyspark', 'mllib', 'to', 'develop', 'variety', 'of', 'models', 'and', 'algorithms', 'for', 'analytic', 'purposes', 'coordinated', 'the', 'execution', 'of', 'a/b', 'tests', 'to', 'measure', 'the', 'effectiveness', 'of', 'personalized', 'recommendation', 'system', 'recommended', 'and', 'evaluated', 'marketing', 'approaches', 'based', 'on', 'quality', 'analytics', 'of', 'customer', 'consuming', 'behavior', 'determined', 'customer', 'satisfaction', 'and', 'helped', 'enhance', 'customer', 'experience', 'using', 'nlp', 'used', 'git', '2.x', 'to', 'apply', 'version', 'control', 'tracked', 'changes', 'in', 'files', 'and', 'coordinated', 'work', 'on', 'the', 'files', 'among', 'multiple', 'team', 'members', 'environment', '3.x', 'python', '3.x', 'oracle', '12c', 'mongodb', '3.3', 'spark', '1.6', '2.0', 'pyspark', 'mllib', 'spark', 'sql', 'git', '2.x', 'atlassian', 'bitbucket', 'augmented', 'production', 'process', 'by', '10', 'by', 'facilitating', 'cross-functional', 'team', 'meetings', 'and', 'providing', 'quality', 'deliverables', 'in', 'time', 'for', 'deployment', 'developed', 'data', 'modelling', 'formulation', 'of', 'statistical', 'equations', 'using', 'advanced', 'statistical', 'forecasting', 'techniques', 'documented', 'the', 'process', 'work', 'flow', 'to', 'describe', 'program', 'development', 'testing', 'application', 'integration', 'coding', 'implementation', 'scoring', 'predictive', 'models', 'as', 'per', 'regulatory', 'requirements', 'ensuring', 'deliverables', 'with', 'psi', 'monitor', 'spark', 'tasks', 'on', 'each', 'and', 'every', 'transformation', 'and', 'action', 'via', 'spark', 'ui', 'and', 'plan', 'partition', 'utilization', 'accordingly', 'for', 'effective', 'performance', 'export', 'data', 'from', 'rdbms', 'to', 'hdfs', 'using', 'scoop', 'import', 'options', 'adept', 'in', 'writing', 'code', 'in', 'and', 't-sql', 'scripts', 'to', 'manipulate', 'data', 'for', 'data', 'loads', 'and', 'extracts', 'developed', 'propensity', 'models', 'for', 'retail', 'liability', 'products', 'to', 'drive', 'proactive', 'campaigns', 'coordinated', 'the', 'execution', 'of', 'a/b', 'tests', 'to', 'measure', 'the', 'effectiveness', 'of', 'personalized', 'recommendation', 'system', 'designed', 'dashboards', 'with', 'tableau', '9.2', 'and', 'meteorjs', 'provided', 'complex', 'reports', 'including', 'summaries', 'charts', 'and', 'graphs', 'to', 'interpret', 'findings', 'to', 'team', 'and', 'stakeholders', 'evaluated', 'and', 'optimized', 'performance', 'of', 'models', 'tuned', 'parameters', 'with', 'exploratory', 'data', 'analysis', 'and', 'k-fold', 'cross', 'validation', 'worked', 'on', 'data', 'cleaning', 'data', 'preparation', 'and', 'feature', 'engineering', 'with', 'python', '3.x', 'including', 'numpy', 'scipy', 'pandas', 'matplotlib', 'seaborn', 'and', 'scikit-learn', 'environment', '3.x', '2.x', 'oracle', '10g', 'hive', '0.11', 'hdfs', 'spark', '1.4', 'tableau', '9.2', 'github', 'involved', 'in', 'design', 'development', 'and', 'support', 'phases', 'of', 'software', 'development', 'life', 'cycle', 'sdlc', 'performed', 'data', 'etl', 'by', 'collecting', 'exporting', 'merging', 'and', 'massaging', 'data', 'from', 'multiple', 'sources', 'and', 'platforms', 'including', 'ssis', 'sql', 'server', 'integration', 'services', 'in', 'sql', 'server', 'worked', 'with', 'cross-functional', 'teams', 'including', 'data', 'engineer', 'team', 'to', 'extract', 'data', 'and', 'rapidly', 'execute', 'from', 'mongodb', 'through', 'mongdb', 'connector', 'for', 'hadoop', 'create', 'hive', 'internal', 'tables', 'with', 'appropriate', 'partitioning', 'and', 'bucketing', 'and', 'write', 'complex', 'queries', 'for', 'data', 'analysis', 'configured', 'oozie', 'work', 'flows', 'to', 'automate', 'data', 'flow', 'performed', 'data', 'cleaning', 'and', 'feature', 'selection', 'using', 'mllib', 'package', 'in', 'pyspark', 'performed', 'partitional', 'clustering', 'into', '100', 'by', 'k-means', 'clustering', 'using', 'scikit-learn', 'package', 'in', 'python', 'where', 'similar', 'hotels', 'for', 'search', 'are', 'grouped', 'together', 'used', 'python', 'to', 'perform', 'anova', 'test', 'to', 'analyze', 'the', 'differences', 'among', 'hotel', 'clusters', 'implemented', 'application', 'of', 'various', 'machine', 'learning', 'algorithms', 'and', 'statistical', 'modeling', 'like', 'decision', 'tree', 'text', 'analytics', 'sentiment', 'analysis', 'naive', 'bayes', 'logistic', 'regression', 'and', 'linear', 'regression', 'using', 'python', 'to', 'determine', 'the', 'accuracy', 'rate', 'of', 'each', 'model', 'determined', 'the', 'most', 'accurately', 'prediction', 'model', 'based', 'on', 'the', 'accuracy', 'rate', 'used', 'text-mining', 'process', 'of', 'reviews', 'to', 'determine', 'customers', 'concentrations', 'delivered', 'analysis', 'support', 'to', 'hotel', 'recommendation', 'and', 'providing', 'an', 'online', 'a/b', 'test', 'designed', 'tableau', 'bar', 'graphs', 'scatter', 'plots', 'and', 'geographical', 'maps', 'to', 'create', 'detailed', 'level', 'summary', 'reports', 'and', 'dashboards', 'developed', 'hybrid', 'model', 'to', 'improve', 'the', 'accuracy', 'rate', 'delivered', 'the', 'results', 'to', 'operation', 'team', 'for', 'better', 'decisions', 'and', 'feedbacks', 'environment', 'python', 'sas', 'tableau', 'mongodb', 'hadoop', 'sql', 'server', 'sdlc', 'etl', 'ssis', 'recommendation', 'systems', 'machine', 'learning', 'algorithms', 'text-mining', 'process', 'a/b', 'test', 'implemented', 'business', 'rules', 'and', 'transformations', 'by', 'developing', 'sql', 'queries', 'stored', 'procedures', 'views', 'and', 'triggers', 'based', 'on', 'client', 'requirements', 'created', 'web', 'pages', 'using', 'xml', 'xslt', 'jsp', 'html', 'and', 'javascript', 'optimized', 'the', 'code', 'and', 'database', 'for', 'maximum', 'performance', 'responsible', 'for', 'deploying', 'web', 'logic', 'application', 'server', 'design', 'and', 'maintain', 'the', 'database', 'to', 'support', 'the', 'application', 'using', 'oracle', 'db', 'prepared', 'the', 'complete', 'data', 'mapping', 'for', 'all', 'the', 'migrated', 'jobs', 'involved', 'in', 'query', 'optimization', 'performance', 'tuning', 'and', 'index', 'creation', 'used', 'singleton', 'factory', 'design', 'pattern', 'dao', 'design', 'patterns', 'based', 'on', 'the', 'application', 'requirements', 'installed', 'and', 'configured', 'tomcat', 'application', 'server', 'and', 'was', 'responsible', 'for', 'various', 'deployments', 'over', 'it', 'performed', 'unit', 'testing', 'using', 'junit', 'test', 'framework', 'used', 'log4j', 'logging', 'framework', 'to', 'write', 'log', 'messages', 'with', 'various', 'levels', 'environment', 'java', 'html', 'javascript', 'xml', 'servlets', 'jsp', 'ejb', 'mvc', 'sql', 'server', 'sql', 'assistant', 'win2000/xp', 'xslt', 'junit', 'ms', 'access', 'uml'], ['designed', 'multiple', 'real-time', 'prediction', 'models', 'based', 'on', 'both', 'supervised', 'and', 'unsupervised', 'learning', 'performed', 'image', 'segmentation', 'on', 'food', 'image', 'data', 'using', 'pyrmeanshiftfiltering', 'in', 'opencv', 'implemented', 'fine-tuned', 'inceptionv3', 'and', 'inceptionresnetv2', 'models', 'with', 'keras', 'to', 'do', 'food', 'recognition', 'on', 'school', 'cafeteria', 'food', 'data', 'set', 'with', 'over', '100', 'classes', 'and', 'achieved', '93', 'accuracy', 'for', 'top', 'classes', 'applied', 'faster', 'r-cnn', 'using', 'tensorflow', 'with', 'vgg16', 'pre-trained', 'model', 'on', 'food', 'images', 'with', 'multiple', 'dishes', 'to', 'detect', 'location', 'of', 'food', 'and', 'recognized', 'food', 'type', 'simultaneously', 'to', 'save', 'time', 'wrote', 'sql', 'queries', 'to', 'get', 'age', 'investment', 'amount', 'and', 'geographic', 'distribution', 'for', 'investors', 'throughout', 'the', 'whole', 'year', 'improved', 'customer', 'experience', 'by', 'analyzing', 'collected', 'information', 'found', 'potential', 'investors', 'of', 'all', 'ages', 'to', 'help', 'company', 'further', 'expand', 'the', 'business', 'regions', 'determined', 'the', 'peak', 'time', 'to', 'invest', 'every', 'day', 'to', 'help', 'engineering', 'team', 'to', 'make', 'proper', 'arrangement', 'found', 'the', 'most', 'popular', 'range', 'of', 'investment', 'amount', 'then', 'eliminated', 'redundant', 'investment', 'options'], ['designed', 'multiple', 'real-time', 'prediction', 'models', 'based', 'on', 'both', 'supervised', 'and', 'unsupervised', 'learning', 'performed', 'image', 'segmentation', 'on', 'food', 'image', 'data', 'using', 'pyrmeanshiftfiltering', 'in', 'opencv', 'implemented', 'fine-tuned', 'inceptionv3', 'and', 'inceptionresnetv2', 'models', 'with', 'keras', 'to', 'do', 'food', 'recognition', 'on', 'school', 'cafeteria', 'food', 'data', 'set', 'with', 'over', '100', 'classes', 'and', 'achieved', '93', 'accuracy', 'for', 'top', 'classes', 'applied', 'faster', 'r-cnn', 'using', 'tensorflow', 'with', 'vgg16', 'pre-trained', 'model', 'on', 'food', 'images', 'with', 'multiple', 'dishes', 'to', 'detect', 'location', 'of', 'food', 'and', 'recognized', 'food', 'type', 'simultaneously', 'to', 'save', 'time', 'wrote', 'sql', 'queries', 'to', 'get', 'age', 'investment', 'amount', 'and', 'geographic', 'distribution', 'for', 'investors', 'throughout', 'the', 'whole', 'year', 'improved', 'customer', 'experience', 'by', 'analyzing', 'collected', 'information', 'found', 'potential', 'investors', 'of', 'all', 'ages', 'to', 'help', 'company', 'further', 'expand', 'the', 'business', 'regions', 'determined', 'the', 'peak', 'time', 'to', 'invest', 'every', 'day', 'to', 'help', 'engineering', 'team', 'to', 'make', 'proper', 'arrangement', 'found', 'the', 'most', 'popular', 'range', 'of', 'investment', 'amount', 'then', 'eliminated', 'redundant', 'investment', 'options'], ['description', 'state', 'street', 'corporation', 'through', 'its', 'subsidiaries', 'provides', 'range', 'of', 'financial', 'products', 'and', 'services', 'to', 'institutional', 'investors', 'worldwide', 'responsibilities', 'setup', 'storage', 'and', 'data', 'analysis', 'tools', 'in', 'amazon', 'web', 'services', 'cloud', 'computing', 'infrastructure', 'worked', 'with', 'several', 'packages', 'including', 'knitr', 'dplyr', 'sparkr', 'causalinfer', 'space-time', 'coded', 'functions', 'to', 'interface', 'with', 'caffe', 'deep', 'learning', 'framework', 'used', 'pandas', 'numpy', 'seaborn', 'scipy', 'matplotlib', 'sci-kit-learn', 'and', 'nltk', 'in', 'python', 'for', 'developing', 'various', 'machine', 'learning', 'algorithms', 'installed', 'and', 'used', 'caffedeep', 'learning', 'framework', 'worked', 'on', 'different', 'data', 'formats', 'such', 'as', 'json', 'xml', 'and', 'performed', 'machine', 'learning', 'algorithms', 'in', 'python', 'implemented', 'end-to-end', 'systems', 'for', 'data', 'analytics', 'data', 'automation', 'and', 'integrated', 'with', 'custom', 'visualization', 'tools', 'using', 'mahout', 'hadoop', 'and', 'mongodb', 'worked', 'as', 'data', 'architects', 'and', 'it', 'architects', 'to', 'understand', 'the', 'movement', 'of', 'data', 'and', 'its', 'storage', 'and', 'er', 'studio', '9.7', 'used', 'data', 'quality', 'validation', 'techniques', 'to', 'validate', 'critical', 'data', 'elements', 'cde', 'and', 'identified', 'various', 'anomalies', 'extensively', 'worked', 'on', 'data', 'modeling', 'tools', 'erwin', 'data', 'modeler', 'to', 'design', 'the', 'data', 'models', 'developed', 'various', 'qlik-view', 'data', 'models', 'by', 'extracting', 'and', 'using', 'the', 'data', 'from', 'various', 'sources', 'files', 'db2', 'excel', 'flat', 'files', 'and', 'big', 'data', 'participated', 'in', 'all', 'phases', 'of', 'data-mining', 'data-collection', 'data-cleaning', 'developing-models', 'validation', 'visualization', 'and', 'performed', 'gap', 'analysis', 'data', 'manipulation', 'and', 'aggregation', 'froma', 'different', 'source', 'using', 'nexus', 'toad', 'business', 'objects', 'powerbi', 'and', 'smartview', 'implemented', 'agile', 'methodology', 'for', 'building', 'an', 'internal', 'application', 'focus', 'on', 'integration', 'overlap', 'and', 'informatica', 'newer', 'commitment', 'to', 'mdm', 'with', 'the', 'acquisition', 'of', 'identity', 'systems', 'good', 'knowledge', 'of', 'hadoop', 'architecture', 'and', 'various', 'components', 'such', 'as', 'hdfs', 'jobtracker', 'task', 'tracker', 'name', 'node', 'data', 'node', 'secondarynamenode', 'and', 'mapreduce', 'concepts', 'as', 'architect', 'delivered', 'various', 'complex', 'olap', 'databases/cubes', 'scorecards', 'dashboards', 'and', 'reports', 'programmed', 'utility', 'in', 'python', 'that', 'used', 'multiple', 'packages', 'scipy', 'numpy', 'pandas', 'implemented', 'classification', 'using', 'supervised', 'algorithms', 'like', 'logistic', 'regression', 'decision', 'trees', 'knn', 'naive', 'bayes', 'designed', 'both', '3nf', 'data', 'models', 'for', 'ods', 'oltp', 'systems', 'and', 'dimensional', 'data', 'models', 'using', 'star', 'and', 'snow', 'flake', 'schemas', 'updated', 'python', 'scripts', 'to', 'match', 'training', 'data', 'with', 'our', 'database', 'stored', 'in', 'aws', 'cloud', 'search', 'so', 'that', 'we', 'would', 'be', 'able', 'to', 'assign', 'each', 'document', 'response', 'label', 'for', 'further', 'classification', 'created', 'sql', 'tables', 'with', 'referential', 'integrity', 'and', 'developed', 'queries', 'using', 'sql', 'sql', 'plus', 'and', 'pl/sql', 'designed', 'and', 'developed', 'use', 'case', 'activity', 'diagrams', 'sequence', 'diagrams', 'ood', 'object', 'oriented', 'design', 'using', 'uml', 'and', 'visio', 'interaction', 'with', 'business', 'analyst', 'smes', 'and', 'other', 'data', 'architects', 'to', 'understand', 'business', 'needs', 'and', 'functionality', 'for', 'various', 'project', 'solutions', 'interaction', 'with', 'business', 'analyst', 'smes', 'and', 'other', 'data', 'architects', 'to', 'understand', 'business', 'needs', 'and', 'functionality', 'for', 'various', 'project', 'solutions', 'identifying', 'and', 'executing', 'process', 'improvements', 'hands-on', 'in', 'various', 'technologies', 'such', 'as', 'oracle', 'informatica', 'and', 'business', 'objects', 'environment', 'aws', 'informatica', 'python', 'hdfs', 'ods', 'oltp', 'oracle', '10g', 'hive', 'olap', 'db2', 'metadata', 'ms', 'excel', 'mainframes', 'ms', 'vision', 'map-reduce', 'rational', 'rose', 'sql', 'mongodb', 'description', 'zions', 'bancorporation', 'financial', 'holding', 'company', 'provides', 'range', 'of', 'banking', 'and', 'related', 'services', 'primarily', 'in', 'arizona', 'california', 'colorado', 'idaho', 'nevada', 'new', 'mexico', 'oregon', 'texas', 'utah', 'washington', 'and', 'wyoming', 'responsibilities', 'analyzed', 'the', 'business', 'requirements', 'of', 'the', 'project', 'by', 'studying', 'the', 'business', 'requirements', 'specification', 'document', 'used', 'singleton', 'factory', 'design', 'pattern', 'fdp', 'dao', 'design', 'patterns', 'based', 'on', 'the', 'application', 'requirements', 'extensively', 'worked', 'on', 'data', 'modeling', 'tools', 'erwin', 'data', 'modeler', 'to', 'design', 'the', 'datamodels', 'designeda', 'mapping', 'to', 'process', 'the', 'incremental', 'changes', 'that', 'exist', 'in', 'the', 'source', 'table', 'whenever', 'source', 'data', 'elements', 'were', 'missing', 'in', 'source', 'tables', 'these', 'were', 'modified/added', 'inconsistency', 'with', 'third', 'normal', 'form', 'based', 'oltp', 'source', 'database', 'designed', 'tables', 'and', 'implemented', 'the', 'naming', 'conventions', 'for', 'logical', 'and', 'physical', 'data', 'models', 'in', 'erwin', '7.0', 'participated', 'inthe', 'conversion', 'of', 'its', 'immigration', 'tracking', 'system', 'visual', 'basic', 'client-server', 'application', 'into', 'asp.net3-tier', 'intranet', 'application', 'performed', 'exploratory', 'data', 'analysis', 'and', 'data', 'visualizations', 'using', 'and', 'tableau', 'perform', 'proper', 'eda', 'uni-variate', 'and', 'bi-variate', 'analysis', 'to', 'understand', 'the', 'intrinsic', 'effect/combined', 'effects', 'worked', 'with', 'data', 'governance', 'data', 'quality', 'data', 'lineage', 'data', 'architect', 'to', 'design', 'various', 'models', 'and', 'processes', 'independently', 'coded', 'new', 'programs', 'and', 'designed', 'tables', 'to', 'load', 'and', 'test', 'the', 'program', 'effectively', 'for', 'the', 'given', 'poc', 'using', 'with', 'big', 'data/hadoop', 'designed', 'data', 'models', 'and', 'data', 'flow', 'diagrams', 'using', 'erwin', 'and', 'ms', 'visio', 'utilized', 'ado.net', 'object', 'model', 'to', 'implement', 'middle-tier', 'components', 'that', 'interacted', 'with', 'ms', 'sql', 'server', '2000', 'database', 'participated', 'in', 'ams', 'alert', 'management', 'system', 'java', 'and', 'sybase', 'project', 'designed', 'sybase', 'database', 'utilizing', 'erwin', 'customized', 'error', 'messages', 'utilizing', 'sp_add', 'message', 'and', 'sp_bindmsg', 'created', 'indexes', 'made', 'query', 'optimizations', 'wrote', 'stored', 'procedures', 'triggers', 'utilizing', 't-sql', 'explained', 'the', 'data', 'model', 'to', 'the', 'other', 'members', 'of', 'thedevelopment', 'team', 'wrote', 'xml', 'parsing', 'module', 'that', 'populates', 'alerts', 'from', 'the', 'xml', 'file', 'into', 'the', 'database', 'tables', 'utilizing', 'java', 'jdbc', 'bea', 'web', 'logic', 'ide', 'and', 'document', 'object', 'model', 'as', 'an', 'architect', 'implemented', 'mdmhub', 'to', 'provide', 'clean', 'consistent', 'data', 'for', 'ansoa', 'implementation', 'developed', 'implemented', 'maintained', 'the', 'conceptual', 'logical', 'physical', 'data', 'models', 'using', 'erwin', 'for', 'forwarding/reverse', 'engineered', 'databases', 'explored', 'and', 'extracted', 'data', 'from', 'source', 'xml', 'in', 'hdfs', 'preparing', 'data', 'for', 'exploratory', 'analysis', 'using', 'data', 'mining', 'environment', 'sql', 'server', '2008r2/2005', 'enterprise', 'ssrs', 'ssis', 'crystal', 'reports', 'hadoop', 'windows', 'enterprise', 'server', '2000', 'dts', 'sql', 'profiler', 'and', 'query', 'analyzer', 'description', 'wright', 'express', 'corporation', 'provides', 'business', 'payment', 'processing', 'and', 'information', 'management', 'solutions', 'in', 'north', 'america', 'the', 'asia', 'pacific', 'and', 'europe', 'it', 'operates', 'in', 'two', 'segments', 'fleet', 'payment', 'solutions', 'and', 'other', 'payment', 'solutions', 'responsibilities', 'coded', 'functions', 'to', 'interface', 'with', 'caffedeeplearningframework', 'working', 'in', 'amazon', 'web', 'services', 'cloud', 'computing', 'environment', 'worked', 'with', 'several', 'packages', 'including', 'knitr', 'dplyr', 'sparkr', 'causal', 'infer', 'space-time', 'implemented', 'end-to-end', 'systems', 'for', 'data', 'analytics', 'data', 'automation', 'and', 'integrated', 'with', 'custom', 'visualization', 'tools', 'using', 'mahout', 'hadoop', 'andmongodb', 'gathering', 'all', 'the', 'data', 'that', 'is', 'required', 'from', 'multiple', 'data', 'sources', 'and', 'creating', 'datasets', 'that', 'will', 'be', 'used', 'in', 'theanalysis', 'performed', 'exploratory', 'data', 'analysis', 'and', 'data', 'visualizations', 'using', 'and', 'tableau', 'perform', 'proper', 'eda', 'uni-variate', 'and', 'bi-variate', 'analysis', 'to', 'understand', 'the', 'intrinsic', 'effect/combined', 'effects', 'worked', 'with', 'data', 'governance', 'data', 'quality', 'data', 'lineage', 'data', 'architect', 'to', 'design', 'various', 'models', 'and', 'processes', 'independently', 'coded', 'new', 'programs', 'and', 'designed', 'tables', 'to', 'load', 'and', 'test', 'the', 'program', 'effectively', 'for', 'the', 'given', 'poc', 'using', 'with', 'big', 'data/hadoop', 'designed', 'data', 'models', 'and', 'data', 'flow', 'diagrams', 'using', 'erwin', 'and', 'ms', 'visio', 'as', 'an', 'architect', 'implemented', 'mdm', 'hub', 'to', 'provide', 'clean', 'consistent', 'data', 'for', 'ansoa', 'implementation', 'developed', 'implemented', 'maintained', 'the', 'conceptual', 'logical', 'physicaldatamodels', 'using', 'erwin', 'for', 'forwarding/reverse', 'engineered', 'databases', 'established', 'data', 'architecture', 'strategy', 'best', 'practices', 'standards', 'and', 'roadmaps', 'lead', 'the', 'development', 'and', 'presentation', 'of', 'dataanalytics', 'data-hub', 'prototype', 'with', 'the', 'help', 'of', 'the', 'other', 'members', 'of', 'the', 'emerging', 'solutions', 'team', 'performed', 'datacleaning', 'and', 'imputation', 'of', 'missing', 'values', 'using', 'worked', 'with', 'hadoopeco', 'system', 'covering', 'hdfs', 'hbase', 'yarn', 'andmapreduce', 'take', 'up', 'ad-hoc', 'requests', 'based', 'on', 'different', 'departments', 'and', 'locations', 'used', 'hive', 'to', 'store', 'the', 'data', 'and', 'perform', 'datacleaning', 'steps', 'for', 'huge', 'datasets', 'created', 'dash', 'boards', 'and', 'visualization', 'on', 'regular', 'basis', 'using', 'ggplot2', 'and', 'tableau', 'creating', 'customized', 'business', 'reports', 'and', 'sharing', 'insights', 'to', 'the', 'management', 'worked', 'with', 'bteq', 'to', 'submit', 'sql', 'statements', 'import', 'and', 'export', 'data', 'and', 'generate', 'reports', 'in', 'teradata', 'interacted', 'with', 'the', 'other', 'departments', 'to', 'understand', 'and', 'identify', 'data', 'needs', 'and', 'requirements', 'and', 'work', 'with', 'other', 'members', 'of', 'the', 'it', 'organization', 'to', 'deliver', 'data', 'visualization', 'and', 'reporting', 'solutions', 'to', 'address', 'those', 'needs', 'environment', 'erwin', 'informatica', 'ods', 'oltp', 'oracle', '10g', 'hive', 'olap', 'db2', 'metadata', 'ms', 'excel', 'mainframes', 'ms', 'visio', 'rational', 'rose', 'and', 'requisite', 'pro', 'hadoop', 'pl/sql', 'etc', 'description', 'quality', 'systems', 'inc', 'together', 'with', 'its', 'subsidiaries', 'develops', 'and', 'markets', 'healthcare', 'information', 'systems', 'in', 'the', 'united', 'states', 'responsibilities', 'statistical', 'modeling', 'with', 'ml', 'to', 'bring', 'insights', 'in', 'data', 'under', 'guidance', 'of', 'principal', 'data', 'scientist', 'data', 'modeling', 'with', 'pig', 'hive', 'impala', 'ingestion', 'with', 'sqoop', 'flume', 'used', 'svn', 'to', 'commit', 'the', 'changes', 'into', 'the', 'main', 'emm', 'application', 'trunk', 'understanding', 'and', 'implementation', 'of', 'text', 'mining', 'concepts', 'graph', 'processing', 'and', 'semi-structured', 'and', 'unstructured', 'data', 'processing', 'worked', 'with', 'ajax', 'api', 'calls', 'to', 'communicate', 'with', 'hadoop', 'through', 'impala', 'connection', 'and', 'sql', 'to', 'render', 'the', 'required', 'data', 'through', 'it', 'theseapi', 'calls', 'are', 'similar', 'to', 'microsoft', 'cognitive', 'api', 'calls', 'good', 'grip', 'on', 'cloudera', 'and', 'hdp', 'ecosystem', 'components', 'used', 'elasticsearch', 'big', 'data', 'to', 'retrieve', 'data', 'intothe', 'application', 'as', 'required', 'performed', 'map', 'reduce', 'programs', 'those', 'are', 'running', 'on', 'the', 'cluster', 'developed', 'multiple', 'mapreduce', 'jobs', 'in', 'java', 'for', 'data', 'cleaning', 'and', 'preprocessing', 'analyzed', 'the', 'partitioned', 'and', 'bucketed', 'data', 'and', 'compute', 'various', 'metrics', 'for', 'reporting', 'involved', 'in', 'loading', 'data', 'from', 'rdbms', 'and', 'weblogs', 'into', 'hdfs', 'using', 'sqoop', 'and', 'flume', 'worked', 'on', 'loading', 'the', 'data', 'from', 'mysql', 'to', 'hbase', 'where', 'necessary', 'using', 'sqoop', 'developed', 'hive', 'queries', 'for', 'analysis', 'across', 'different', 'banners', 'extracted', 'data', 'from', 'twitter', 'using', 'java', 'and', 'twitter', 'api', 'parsed', 'json', 'formatted', 'twitter', 'data', 'and', 'uploaded', 'tothe', 'database', 'launching', 'amazon', 'ec2', 'cloud', 'instances', 'using', 'amazon', 'images', 'linux', 'ubuntu', 'and', 'configuring', 'launched', 'instances', 'with', 'respect', 'to', 'specific', 'applications', 'exported', 'the', 'result', 'set', 'from', 'hive', 'to', 'mysql', 'using', 'sqoop', 'after', 'processing', 'the', 'data', 'analyzed', 'the', 'data', 'by', 'performing', 'hive', 'queries', 'and', 'running', 'pig', 'scripts', 'to', 'study', 'customer', 'behavior', 'have', 'hands-on', 'experience', 'working', 'withsequence', 'files', 'avro', 'har', 'file', 'formats', 'and', 'compression', 'used', 'hive', 'to', 'partition', 'and', 'bucket', 'data', 'experience', 'in', 'writing', 'mapreduce', 'programs', 'with', 'java', 'api', 'to', 'cleanse', 'structured', 'and', 'unstructured', 'data', 'wrote', 'pig', 'scripts', 'to', 'perform', 'etl', 'procedures', 'on', 'the', 'data', 'in', 'hdfs', 'created', 'hbase', 'tables', 'to', 'store', 'various', 'data', 'formats', 'of', 'data', 'coming', 'from', 'different', 'portfolios', 'worked', 'on', 'improvingthe', 'performance', 'of', 'existing', 'pig', 'and', 'hive', 'queries', 'environment', 'sql/server', 'oracle', 'ms-office', 'teradata', 'informatica', 'er', 'studio', 'xml', 'business', 'objects', 'hdfs', 'teradata', '14.1', 'json', 'hadoop', 'hdfs', 'mapreduce', 'pig', 'spark', 'studio', 'mahout', 'java', 'hive', 'aws', 'description', 'virtela', 'an', 'ntt', 'communications', 'company', 'is', 'the', 'smart', 'alternative', 'for', 'enterprise', 'networking', 'and', 'virtualized', 'it', 'services', 'responsibilities', 'worked', 'with', 'large', 'amounts', 'of', 'structured', 'and', 'unstructured', 'data', 'knowledge', 'of', 'machine', 'learning', 'concepts', 'generalized', 'linear', 'models', 'regularization', 'random', 'forest', 'time', 'series', 'models', 'etc', 'worked', 'in', 'business', 'intelligence', 'tools', 'and', 'visualization', 'tools', 'such', 'as', 'business', 'objects', 'tableau', 'chartio', 'etc', 'deployed', 'gui', 'pages', 'by', 'using', 'jsp', 'jstl', 'html', 'dhtml', 'xhtml', 'css', 'javascript', 'and', 'ajax', 'configured', 'the', 'project', 'on', 'websphere', '6.1', 'application', 'servers', 'implemented', 'the', 'online', 'application', 'by', 'using', 'core', 'java', 'jdbc', 'jsp', 'servlets', 'and', 'ejb', '1.1', 'web', 'services', 'soap', 'wsdl', 'handled', 'end-to-end', 'project', 'from', 'data', 'discovery', 'to', 'model', 'deployment', 'monitoring', 'the', 'automated', 'loading', 'processes', 'communicated', 'with', 'other', 'health', 'care', 'info', 'by', 'using', 'web-services', 'with', 'the', 'help', 'of', 'soap', 'wsdl', 'jax-rpc', 'used', 'singleton', 'factory', 'design', 'pattern', 'dao', 'design', 'patterns', 'based', 'on', 'the', 'application', 'requirements', 'used', 'sax', 'and', 'dom', 'parsers', 'to', 'parse', 'the', 'raw', 'xml', 'documents', 'used', 'rad', 'as', 'development', 'ide', 'for', 'web', 'applications', 'preparing', 'and', 'executing', 'unit', 'test', 'cases', 'used', 'log4j', 'logging', 'framework', 'to', 'write', 'log', 'messages', 'with', 'various', 'levels', 'involved', 'in', 'fixing', 'bugs', 'and', 'minor', 'enhancements', 'to', 'the', 'front-end', 'modules', 'implemented', 'microsoft', 'visio', 'and', 'rational', 'rose', 'for', 'designing', 'the', 'use', 'case', 'diagrams', 'class', 'model', 'sequence', 'diagrams', 'and', 'activity', 'diagrams', 'for', 'sdlc', 'process', 'of', 'the', 'application', 'doing', 'functional', 'and', 'technical', 'reviews', 'maintenance', 'in', 'the', 'testing', 'team', 'for', 'system', 'testing/integration/uat', 'guaranteeing', 'quality', 'in', 'the', 'deliverables', 'conducted', 'design', 'reviews', 'and', 'technical', 'reviews', 'with', 'other', 'project', 'stakeholders', 'was', 'part', 'of', 'the', 'complete', 'life', 'cycle', 'of', 'the', 'project', 'from', 'the', 'requirements', 'to', 'the', 'production', 'support', 'created', 'test', 'plan', 'documents', 'for', 'all', 'back-end', 'database', 'modules', 'implemented', 'the', 'project', 'in', 'linux', 'environment', 'environment', 'erwin', 'tableau', 'mdm', 'qlikview', 'mllib', 'pl/sql', 'hdfs', 'teradata', 'json', 'hadoop', 'hdfs', 'mapreduce', 'pig', 'spark', 'studio', 'mahout', 'java', 'hive', 'aws', 'description', 'founded', 'in', '2006', 'people', 'tech', 'is', 'an', 'emerging', 'leader', 'in', 'the', 'enterprise', 'applications', 'and', 'it', 'services', 'marketplace', 'people', 'tech', 'draws', 'its', 'expertise', 'from', 'strategic', 'partnerships', 'with', 'technology', 'leaders', 'like', 'microsoft', 'oracle', 'and', 'sap', 'and', 'combines', 'that', 'with', 'the', 'deep', 'understanding', 'of', 'its', 'employees', 'responsibilities', 'developed', 'internet', 'traffic', 'scoring', 'platform', 'for', 'ad', 'networks', 'advertisers', 'and', 'publishers', 'rule', 'engine', 'site', 'scoring', 'keyword', 'scoring', 'lift', 'measurement', 'linkage', 'analysis', 'responsible', 'for', 'defining', 'the', 'key', 'identifiers', 'for', 'each', 'mapping/interface', 'clients', 'include', 'ebay', 'click', 'forensics', 'cars.com', 'turn.com', 'microsoft', 'and', 'look', 'smart', 'implementation', 'of', 'metadata', 'repository', 'maintaining', 'data', 'quality', 'data', 'cleanup', 'procedures', 'transformations', 'data', 'standards', 'data', 'governance', 'program', 'scripts', 'stored', 'procedures', 'triggers', 'and', 'execution', 'of', 'test', 'plans', 'designed', 'the', 'architecture', 'for', 'one', 'of', 'the', 'first', 'analytics', '3.0', 'online', 'platforms', 'all-purpose', 'scoring', 'with', 'on-demand', 'saas', 'api', 'services', 'currently', 'under', 'implementation', 'web', 'crawling', 'and', 'text', 'mining', 'techniques', 'to', 'score', 'referral', 'domains', 'generate', 'keyword', 'taxonomies', 'and', 'assess', 'commercial', 'value', 'of', 'bid', 'keywords', 'developed', 'new', 'hybrid', 'statistical', 'and', 'data', 'mining', 'technique', 'known', 'as', 'hidden', 'decision', 'trees', 'and', 'hidden', 'forests', 'reverse', 'engineering', 'of', 'keyword', 'pricing', 'algorithms', 'in', 'the', 'context', 'of', 'pay-per-click', 'arbitrage', 'coordinated', 'meetings', 'with', 'vendors', 'to', 'define', 'requirements', 'and', 'system', 'interaction', 'agreement', 'documentation', 'between', 'client', 'and', 'vendor', 'system', 'automated', 'bidding', 'for', 'advertiser', 'campaigns', 'based', 'either', 'on', 'keyword', 'or', 'category', 'run-of-site', 'bidding', 'creation', 'of', 'multimillion', 'bid', 'keyword', 'lists', 'using', 'extensive', 'web', 'crawling', 'identification', 'of', 'metrics', 'to', 'measure', 'the', 'quality', 'of', 'each', 'list', 'yield', 'or', 'coverage', 'volume', 'and', 'keyword', 'average', 'financial', 'value', 'enterprise', 'metadata', 'library', 'with', 'any', 'changes', 'or', 'updates', 'document', 'data', 'quality', 'and', 'traceability', 'documents', 'for', 'each', 'source', 'interface', 'establish', 'standards', 'of', 'procedures', 'generate', 'weekly', 'and', 'monthly', 'asset', 'inventory', 'reports', 'environment', 'erwin', 'sql', 'server', '2000/2005', 'windows', 'xp/nt/2000', 'oracle', 'ms-dts', 'uml', 'uat', 'sql', 'loader', 'ood', 'oltp', 'pl/sql', 'ms', 'visio', 'informatica'], ['contribute', 'to', 'research', 'in', 'multimedia', 'data', 'analysis', 'design', 'an', 'methodology', 'for', 'multimedia', 'data', 'analysis', 'for', 'voice', 'data', 'image', 'data', 'category', 'data', 'text', 'data', 'design', 'video', 'sentiment', 'analysis', 'model', 'will', 'apply', 'to', 'commercial', 'public', 'speech', 'plan', 'to', 'combine', 'it', 'with', 'text', 'sentiment', 'analysis', 'model', 'to', 'mine', 'alternative', 'data', 'from', 'video', 'design', 'and', 'implement', 'of', 'text', 'sentiment', 'analysis', 'ml', 'components', 'applied', 'to', 'the', 'commercial', 'conference', 'call', 'automatically', 'abstract', 'alternative', 'data', 'from', 'text', 'file', 'implementation', 'and', 'develop', 'the', 'cross-section', 'of', 'stock', 'return', 'analysis', 'model', 'applied', 'to', 'annual', 'accounting', 'data', 'come', 'from', 'crsp/compustat', 'files', 'pyspark', 'mapreduce', 'contributed', 'to', 'developing', 'image', 'recognition', 'research', 'project', 'developed', 'and', 'implemented', 'fine-grained', 'image', 'classification', 'model', 'applied', 'to', 'the', 'agricultural', 'product', 'image', 'designed', 'implemented', 'and', 'developed', 'the', 'auto-news', 'system', 'include', 'auto-news', 'mining', 'system', 'news', 'classification', 'system', 'news', 'popularity', 'calculation', 'system', 'this', 'program', 'will', 'automatically', 'mine', 'news', 'from', 'websites', 'then', 'do', 'analysis', 'and', 'classification', 'finally', 'calculate', 'the', 'popularity', 'of', 'each', 'news', 'and', 'save', 'the', 'data', 'to', 'the', 'database', 'news', 'classification', 'system', 'implemented', 'by', 'rnn', 'and', 'w2v', 'encoding', 'model', 'finally', 'achieved', '92.5', 'accuracy', 'of', 'the', 'validation', 'set', 'implemented', 'web', 'crawler', 'utilize', 'machine', 'learning', 'mining', 'data', 'from', 'the', 'web', 'source'], ['developing', 'cognitive', 'services', 'ai', 'content', 'recommendations', 'home', 'security', 'optimization', 'etc', 'security', 'intelligence', 'developed', 'new', 'threat', 'management', 'platform', 'for', 'large', 'enterprises', 'and', 'security', 'operation', 'centers', 'designed', 'knowledge', 'graph', 'malware', 'play-books', 'and', 'info-seekers', 'for', 'ai', 'based', 'threat', 'filters', 'developed', 'advanced', 'machine', 'learning', 'algorithms', 'cyber', 'security', 'threat', 'intelligence', 'products', 'developed', 'ai', 'algorithms', 'to', 'detect', 'dns', 'tunneling', 'data', 'leak', 'fast', 'flux', 'net', 'dga', 'malware', 'led', 'and', 'completed', 'external', 'contracts', '3m', '50', 'and', 'internal', 'projects', 'multi-projects', 'per', 'year', 'as', 'pm', 'pi', 'and', 'key', 'contributor', 'in', 'technical', 'areas', 'of', 'aerospace', 'systems', 'and', 'defense', 'technologies', 'big', 'data', 'analytics', 'text', 'analytics', 'cyber', 'security', 'anomaly', 'detection', 'etc', 'have', 'completed', 'over', '12', 'contracts/programs', 'by', 'using', 'big', 'data', 'analytics', 'saas', 'machine', 'learning', 'hadoop/spark', 'preventive', 'maintenance', 'predictive', 'and', 'text', 'analytics', 'and', 'cyber', 'security', 'etc', '2008', 'army', 'contract', 'w15p7t-08-c-p405', 'phase', 'ii', 'awarded', 'http', 'web.sba.gov/tech-net/public/dsp_award.cfm', 'imawrdseqnmb=81489', 'phs=11', 'human', 'neocortex-inspired', 'intelligent', 'database', 'won', 'and', 'completed', 'federal', 'contracts', 'as', 'sole', 'pi', 'successfully', 'contributed', 'and', 'completed', '15', 'contracts', 'and', 'programs', 'in', 'data-to-intelligence', 'and', 'cyber', 'security', 'over', '10', 'satisfactorily', 'built/led', 'teams', 'of', '10', 'scientists', 'and', 'software', 'developers', 'successfully', 'completed', '20', 'more', 'data-to-intelligence', 'software', 'ai', 'prototypes', 'and', 'innovative', 'solutions', 'via', 'the', 'funded', 'programs'], ['description', 'massachusetts', 'mutual', 'life', 'insurance', 'company', 'operates', 'as', 'mutual', 'life', 'insurance', 'company', 'in', 'the', 'united', 'states', 'it', 'offers', 'life', 'disability', 'income', 'and', 'long-term', 'care', 'insurance', 'responsibilities', 'performed', 'data', 'profiling', 'to', 'learn', 'about', 'behavior', 'with', 'various', 'features', 'such', 'as', 'traffic', 'pattern', 'location', 'time', 'date', 'and', 'time', 'etc', 'application', 'of', 'various', 'machine', 'learning', 'algorithms', 'and', 'statistical', 'modeling', 'like', 'decision', 'trees', 'regressionmodels', 'neural', 'networks', 'svm', 'clustering', 'to', 'identify', 'volume', 'using', 'scikit-learn', 'package', 'in', 'python', 'matlab', 'utilized', 'spark', 'scala', 'hadoop', 'hbase', 'cassandra', 'mongodb', 'kafka', 'spark', 'streaming', 'mllib', 'python', 'broad', 'variety', 'of', 'machine', 'learning', 'methods', 'including', 'classifications', 'regressions', 'dimensionally', 'reduction', 'etc', 'and', 'utilized', 'the', 'engine', 'to', 'increase', 'user', 'lifetime', 'by', '45', 'and', 'triple', 'user', 'conversations', 'for', 'target', 'categories', 'developed', 'spark/scala', 'python', 'for', 'regular', 'expression', 'regex', 'project', 'in', 'the', 'hadoop/hive', 'environment', 'with', 'linux/windows', 'for', 'big', 'data', 'resources', 'used', 'clustering', 'technique', 'k-means', 'to', 'identify', 'outliers', 'and', 'to', 'classify', 'unlabeled', 'data', 'evaluated', 'models', 'using', 'cross', 'validation', 'log', 'loss', 'function', 'roc', 'curves', 'and', 'used', 'auc', 'for', 'feature', 'selection', 'design', 'and', 'develop', 'state-of-the-art', 'deep-learning', 'machine-learning', 'algorithms', 'for', 'analyzing', 'the', 'image', 'and', 'video', 'data', 'among', 'others', 'develop', 'and', 'implement', 'innovative', 'ai', 'and', 'machine', 'learning', 'tools', 'that', 'will', 'be', 'used', 'in', 'the', 'risk', 'analyze', 'traffic', 'patterns', 'by', 'calculating', 'autocorrelation', 'with', 'different', 'time', 'lags', 'ensured', 'that', 'the', 'model', 'has', 'low', 'false', 'positive', 'rate', 'addressed', 'overfitting', 'by', 'implementing', 'of', 'the', 'algorithm', 'regularization', 'methods', 'like', 'l2', 'and', 'l1', 'used', 'principal', 'component', 'analysis', 'in', 'feature', 'engineering', 'to', 'analyze', 'high', 'dimensional', 'data', 'created', 'and', 'designed', 'reports', 'that', 'will', 'use', 'gathered', 'metrics', 'to', 'infer', 'and', 'draw', 'logical', 'conclusions', 'of', 'past', 'and', 'future', 'behavior', 'performed', 'multinomial', 'logistic', 'regression', 'randomforest', 'decision', 'tree', 'svm', 'to', 'classify', 'package', 'is', 'going', 'to', 'deliver', 'on', 'time', 'for', 'the', 'new', 'route', 'performed', 'data', 'analysis', 'by', 'using', 'hive', 'to', 'retrieve', 'the', 'data', 'from', 'hadoopcluster', 'sql', 'to', 'retrieve', 'data', 'from', 'oracle', 'database', 'used', 'mllib', 'spark', 'machine', 'learning', 'library', 'to', 'build', 'and', 'evaluate', 'different', 'models', 'implemented', 'rule', 'based', 'expertise', 'system', 'from', 'the', 'results', 'of', 'exploratory', 'analysis', 'and', 'information', 'gathered', 'from', 'the', 'people', 'from', 'different', 'departments', 'performed', 'data', 'cleaning', 'features', 'scaling', 'features', 'engineering', 'using', 'pandas', 'and', 'numpy', 'packages', 'in', 'python', 'automatic', 'categorization', 'on', 'drug', 'efficacy', 'and', 'side', 'effect', 'extraction', 'were', 'performed', 'counter', 'intuitive', 'predictors', 'were', 'identified', 'using', 'machine-learning', 'methods', 'developed', 'mapreduce', 'pipeline', 'for', 'feature', 'extraction', 'using', 'hive', 'created', 'data', 'qualityscripts', 'using', 'sql', 'and', 'hive', 'to', 'validate', 'successful', 'data', 'load', 'and', 'quality', 'of', 'the', 'data', 'created', 'various', 'types', 'of', 'data', 'visualizations', 'using', 'python', 'and', 'tableau', 'communicated', 'the', 'results', 'with', 'operations', 'team', 'for', 'taking', 'best', 'decisions', 'collected', 'data', 'needs', 'and', 'requirements', 'by', 'interacting', 'with', 'the', 'other', 'departments', 'environment', 'python', '2.x', 'cdh5', 'hdfs', 'hadoop', '2.3', 'hive', 'impala', 'linux', 'spark', 'tableau', 'desktop', 'sql', 'server', '2012', 'microsoft', 'excel', 'matlab', 'spark', 'sql', 'pyspark', 'machine', 'learning', 'description', 'the', 'bank', 'of', 'tokyo-mitsubishi', 'ufj', 'ltd', 'provides', 'various', 'banking', 'and', 'financial', 'services', 'to', 'individuals', 'and', 'corporate', 'customers', 'in', 'the', 'americas', 'europe', 'the', 'middle', 'east', 'africa', 'asia', 'and', 'oceania', 'the', 'company', 'operates', 'through', 'retail', 'banking', 'business', 'unit', 'corporate', 'banking', 'business', 'unit', 'global', 'business', 'unit', 'global', 'markets', 'unit', 'and', 'other', 'units', 'segments', 'it', 'offers', 'corporate', 'and', 'investment', 'banking', 'services', 'including', 'syndication', 'and', 'cross', 'border', 'syndication', 'loans', 'responsibilities', 'provided', 'configuration', 'management', 'and', 'build', 'support', 'for', 'more', 'than', 'different', 'applications', 'built', 'and', 'deployed', 'to', 'the', 'production', 'and', 'lower', 'environments', 'implemented', 'public', 'segmentation', 'using', 'unsupervised', 'machine', 'learning', 'algorithms', 'by', 'implementing', 'k-means', 'algorithm', 'using', 'pyspark', 'explored', 'and', 'extracted', 'data', 'from', 'source', 'xml', 'in', 'hdfs', 'preparing', 'data', 'for', 'exploratory', 'analysis', 'using', 'data', 'munging', 'responsible', 'for', 'different', 'data', 'mapping', 'activities', 'from', 'source', 'systems', 'to', 'teradata', 'handled', 'importing', 'data', 'from', 'various', 'data', 'sources', 'performed', 'transformations', 'using', 'hive', 'map', 'reduce', 'and', 'loaded', 'data', 'into', 'hdfs', 'used', 'and', 'python', 'for', 'exploratory', 'data', 'analysis', 'a/b', 'testing', 'anova', 'test', 'and', 'hypothesis', 'test', 'to', 'compare', 'and', 'identify', 'the', 'effectiveness', 'of', 'creative', 'campaigns', 'created', 'clusters', 'to', 'classify', 'control', 'and', 'test', 'groups', 'and', 'conducted', 'group', 'campaigns', 'analyzed', 'and', 'calculated', 'the', 'lifetime', 'cost', 'of', 'everyone', 'in', 'the', 'welfare', 'system', 'using', '20', 'years', 'of', 'historical', 'data', 'identify', 'and', 'assess', 'available', 'machine', 'learning', 'and', 'statistical', 'analysis', 'libraries', 'including', 'repressors', 'classifiers', 'statistical', 'tests', 'and', 'clustering', 'algorithms', 'innovate', 'and', 'leverage', 'machine', 'learning', 'data', 'mining', 'and', 'statistical', 'techniques', 'to', 'create', 'new', 'scalable', 'solutions', 'for', 'business', 'problems', 'developed', 'linuxshell', 'scripts', 'by', 'using', 'nzsql/nzload', 'utilities', 'to', 'load', 'data', 'from', 'flat', 'files', 'to', 'netezza', 'database', 'developed', 'triggers', 'stored', 'procedures', 'functions', 'and', 'packages', 'using', 'cursors', 'and', 'ref', 'cursor', 'concepts', 'associated', 'with', 'the', 'project', 'using', 'pl/sql', 'created', 'various', 'types', 'of', 'data', 'visualizations', 'using', 'python', 'and', 'tableau', 'used', 'python', 'sql', 'to', 'create', 'statistical', 'algorithms', 'involving', 'multivariate', 'regression', 'linearregression', 'pca', 'random', 'forest', 'models', 'decision', 'trees', 'support', 'vector', 'machine', 'for', 'estimating', 'the', 'risks', 'of', 'welfare', 'dependency', 'identified', 'and', 'targeted', 'welfare', 'high-risk', 'groups', 'with', 'machinelearningalgorithms', 'conducted', 'campaigns', 'and', 'run', 'real-time', 'trials', 'to', 'determine', 'what', 'works', 'fast', 'and', 'track', 'the', 'impact', 'of', 'different', 'initiatives', 'developed', 'tableau', 'visualizations', 'and', 'dashboards', 'using', 'tableau', 'desktop', 'used', 'graphical', 'entity-relationship', 'diagramming', 'to', 'create', 'new', 'database', 'design', 'via', 'easy', 'to', 'use', 'graphical', 'interface', 'created', 'multiple', 'custom', 'sqlqueries', 'in', 'teradatasqlworkbench', 'to', 'prepare', 'the', 'right', 'data', 'sets', 'for', 'tableau', 'dashboards', 'perform', 'analyses', 'such', 'as', 'regression', 'analysis', 'logistic', 'regression', 'discriminant', 'analysis', 'cluster', 'analysis', 'using', 'sas', 'programming', 'used', 'meta', 'data', 'tool', 'for', 'importing', 'metadata', 'from', 'repository', 'new', 'job', 'categories', 'and', 'creating', 'new', 'data', 'elements', 'scheduled', 'the', 'task', 'for', 'weekly', 'updates', 'and', 'running', 'the', 'model', 'in', 'workflow', 'automated', 'the', 'entire', 'process', 'flow', 'in', 'generating', 'the', 'analysis', 'and', 'reports', 'environment', '3.x', 'hdfs', 'hadoop', '2.3', 'pig', 'hive', 'linux', 'r-studio', 'tableau', '10', 'sql', 'server', 'ms', 'excel', 'pyspark', 'machine', 'learning', 'description', 'tripadvisor', 'inc', 'is', 'an', 'american', 'travel', 'website', 'company', 'providing', 'reviews', 'of', 'travel-related', 'content', 'it', 'also', 'includes', 'interactive', 'travel', 'forums', 'tripadvisor', 'was', 'an', 'early', 'adopter', 'of', 'user-generated', 'content', 'the', 'website', 'services', 'are', 'free', 'to', 'users', 'who', 'provide', 'most', 'of', 'the', 'content', 'and', 'the', 'website', 'is', 'supported', 'by', 'an', 'advertising', 'business', 'model', 'responsibilities', 'involved', 'in', 'design', 'development', 'and', 'support', 'phases', 'of', 'software', 'development', 'life', 'cycle', 'sdlc', 'performed', 'data', 'etl', 'by', 'collecting', 'exporting', 'merging', 'and', 'massaging', 'data', 'from', 'multiple', 'sources', 'and', 'platforms', 'including', 'ssis', 'sql', 'server', 'integration', 'services', 'in', 'sql', 'server', 'worked', 'with', 'cross-functional', 'teams', 'including', 'data', 'engineer', 'team', 'to', 'extract', 'data', 'and', 'rapidly', 'execute', 'from', 'mongodb', 'through', 'mongdb', 'connector', 'for', 'hadoop', 'performed', 'data', 'cleaning', 'and', 'feature', 'selection', 'using', 'mllib', 'package', 'in', 'pyspark', 'performed', 'partitional', 'clustering', 'into', '100', 'by', 'k-means', 'clustering', 'using', 'scikit-learn', 'package', 'in', 'python', 'where', 'similar', 'hotels', 'for', 'search', 'are', 'grouped', 'together', 'used', 'python', 'to', 'perform', 'anova', 'test', 'to', 'analyze', 'the', 'differences', 'among', 'hotel', 'clusters', 'implemented', 'application', 'of', 'various', 'machine', 'learning', 'algorithms', 'and', 'statistical', 'modeling', 'like', 'decision', 'tree', 'naive', 'bayes', 'logistic', 'regression', 'and', 'linear', 'regression', 'using', 'python', 'to', 'determine', 'the', 'accuracy', 'rate', 'of', 'each', 'model', 'created', 'machine', 'learning', 'and', 'statistical', 'methods', 'svm', 'crf', 'hmm', 'sequential', 'tagging', 'or', 'willingness', 'to', 'intensely', 'learn', 'develop', 'and', 'implement', 'innovative', 'ai', 'and', 'machine', 'learning', 'tools', 'that', 'will', 'be', 'used', 'in', 'the', 'risk', 'determined', 'the', 'most', 'accurately', 'prediction', 'model', 'based', 'on', 'the', 'accuracy', 'rate', 'used', 'text-mining', 'process', 'of', 'reviews', 'to', 'determine', 'customers', 'concentrations', 'delivered', 'analysis', 'support', 'to', 'hotel', 'recommendation', 'and', 'providing', 'an', 'online', 'a/b', 'test', 'designed', 'tableau', 'bar', 'graphs', 'scattered', 'plots', 'and', 'geographical', 'maps', 'to', 'create', 'detailed', 'level', 'summary', 'reports', 'and', 'dashboards', 'developed', 'hybrid', 'model', 'to', 'improve', 'the', 'accuracy', 'rate', 'delivered', 'the', 'results', 'to', 'operation', 'team', 'for', 'better', 'decisions', 'and', 'feedbacks', 'environment', 'python', 'pyspark', 'tableau', 'mongodb', 'hadoop', 'sql', 'server', 'sdlc', 'etl', 'ssis', 'recommendation', 'systems', 'machine', 'learning', 'algorithms', 'text-mining', 'process', 'a/b', 'test', 'machine', 'learning', 'description', 'bank', 'of', 'america', 'is', 'multinational', 'banking', 'and', 'financial', 'services', 'corporation', 'it', 'is', 'ranked', '2nd', 'on', 'the', 'list', 'of', 'largest', 'banks', 'in', 'the', 'united', 'states', 'by', 'assets', 'as', 'of', '2016', 'bank', 'of', 'america', 'was', 'the', '26th', 'largest', 'company', 'in', 'the', 'united', 'states', 'by', 'total', 'revenue', 'responsibilities', 'participated', 'in', 'all', 'phases', 'of', 'research', 'including', 'data', 'collection', 'data', 'cleaning', 'data', 'mining', 'developing', 'models', 'and', 'visualizations', 'collaborated', 'with', 'data', 'engineers', 'and', 'operation', 'team', 'to', 'collect', 'data', 'from', 'internal', 'system', 'to', 'fit', 'the', 'analytical', 'requirements', 'redefined', 'many', 'attributes', 'and', 'relationships', 'and', 'cleansed', 'unwanted', 'tables/columns', 'using', 'sql', 'queries', 'utilized', 'spark', 'sql', 'api', 'in', 'pyspark', 'to', 'extract', 'and', 'load', 'data', 'and', 'perform', 'sql', 'queries', 'performed', 'data', 'imputation', 'using', 'scikit-learn', 'package', 'in', 'python', 'performed', 'data', 'processing', 'using', 'python', 'libraries', 'like', 'numpy', 'and', 'pandas', 'worked', 'with', 'data', 'analysis', 'using', 'ggplot2', 'library', 'in', 'to', 'do', 'data', 'visualizations', 'for', 'better', 'understanding', 'of', 'customers', 'behaviors', 'visually', 'plotted', 'data', 'using', 'tableau', 'for', 'dashboards', 'and', 'reports', 'implemented', 'statistical', 'modeling', 'with', 'xgboost', 'machine', 'learning', 'software', 'package', 'using', 'to', 'determine', 'the', 'predicted', 'probabilities', 'of', 'each', 'model', 'delivered', 'the', 'results', 'with', 'operation', 'team', 'for', 'better', 'decisions', 'environment', 'python', 'sql', 'tableau', 'spark', 'machine', 'learning', 'software', 'package', 'recommendation', 'systems', 'description', 'cenvien', 'technologies', 'gather', 'the', 'requirements', 'by', 'listening', 'and', 'understanding', 'to', 'the', 'client', 'business', 'requirement', 'to', 'deliver', 'quality', 'products', 'it', 'is', 'highly', 'qualified', 'and', 'strongly', 'dedicated', 'developing', 'team', 'that', 'produces', 'unique', 'solutions', 'responsibilities', 'developed', 'entire', 'frontend', 'and', 'backend', 'modules', 'using', 'python', 'on', 'django', 'web', 'framework', 'implemented', 'the', 'presentation', 'layer', 'with', 'html', 'css', 'and', 'javascript', 'involved', 'in', 'writing', 'stored', 'procedures', 'using', 'oracle', 'optimized', 'the', 'database', 'queries', 'to', 'improve', 'the', 'performance', 'designed', 'and', 'developed', 'data', 'management', 'system', 'using', 'oracle', 'environment', 'mysql', 'oracle', 'html5', 'css3', 'javascript', 'shell', 'linux', 'windows', 'django', 'python', 'description', 'as', 'backend', 'developer', 'of', 'web', 'applications', 'and', 'data', 'science', 'infrastructure', 'the', 'main', 'area', 'of', 'focus', 'is', 'to', 'come', 'up', 'with', 'comprehensive', 'solutions', 'that', 'need', 'massive', 'capacity', 'and', 'throughput', 'responsibilities', 'effectively', 'communicated', 'with', 'the', 'stakeholders', 'to', 'gather', 'requirements', 'for', 'different', 'projects', 'used', 'mysql', 'db', 'package', 'and', 'python-mysql', 'connector', 'for', 'writing', 'and', 'executing', 'several', 'mysql', 'database', 'queries', 'from', 'python', 'created', 'functions', 'triggers', 'views', 'and', 'stored', 'procedures', 'using', 'my', 'sql', 'worked', 'closely', 'with', 'back-end', 'developer', 'to', 'find', 'ways', 'to', 'push', 'the', 'limits', 'of', 'existing', 'web', 'technology', 'involved', 'in', 'the', 'code', 'review', 'meetings', 'environment', 'python', 'mysql']]\n"
     ]
    }
   ],
   "source": [
    "#####################   CNN\n",
    "import pandas as pd\n",
    "import nltk,string\n",
    "import csv\n",
    "# Load data\n",
    "\n",
    "with open(\"indeed_scraped_data_science.csv\", \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "    reader = csv.reader(f, delimiter=',')    \n",
    "    text = [(row[8]) for row in reader]\n",
    "# tokenize each document into a list of unigrams\n",
    "# strip punctuations and leading/trailing spaces from unigrams\n",
    "# only unigrams with 2 or more characters are taken\n",
    "sentences=[ [token.strip(string.punctuation).strip() \\\n",
    "             for token in nltk.word_tokenize(doc.lower()) \\\n",
    "                 if token not in string.punctuation and \\\n",
    "                 len(token.strip(string.punctuation).strip())>=2]\\\n",
    "             for doc in text]\n",
    "print(sentences[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-26 01:31:10,357 : INFO : collecting all words and their counts\n",
      "2018-04-26 01:31:10,359 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-04-26 01:31:10,593 : INFO : collected 44399 word types from a corpus of 1026764 raw words and 1818 sentences\n",
      "2018-04-26 01:31:10,594 : INFO : Loading a fresh vocabulary\n",
      "2018-04-26 01:31:10,681 : INFO : min_count=5 retains 10583 unique words (23% of original 44399, drops 33816)\n",
      "2018-04-26 01:31:10,682 : INFO : min_count=5 leaves 970554 word corpus (94% of original 1026764, drops 56210)\n",
      "2018-04-26 01:31:10,738 : INFO : deleting the raw counts dictionary of 44399 items\n",
      "2018-04-26 01:31:10,747 : INFO : sample=0.001 downsamples 31 most-common words\n",
      "2018-04-26 01:31:10,748 : INFO : downsampling leaves estimated 777965 word corpus (80.2% of prior 970554)\n",
      "2018-04-26 01:31:10,807 : INFO : estimated required memory for 10583 words and 200 dimensions: 22224300 bytes\n",
      "2018-04-26 01:31:10,809 : INFO : resetting layer weights\n",
      "2018-04-26 01:31:11,046 : INFO : training model with 4 workers on 10583 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-04-26 01:31:12,085 : INFO : EPOCH 1 - PROGRESS: at 67.16% examples, 573384 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-26 01:31:12,426 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-26 01:31:12,446 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-26 01:31:12,448 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-26 01:31:12,450 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-26 01:31:12,452 : INFO : EPOCH - 1 : training on 1026764 raw words (778132 effective words) took 1.4s, 559593 effective words/s\n",
      "2018-04-26 01:31:13,461 : INFO : EPOCH 2 - PROGRESS: at 75.69% examples, 697724 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-26 01:31:13,532 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-26 01:31:13,548 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-26 01:31:13,551 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-26 01:31:13,558 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-26 01:31:13,559 : INFO : EPOCH - 2 : training on 1026764 raw words (778252 effective words) took 1.1s, 705425 effective words/s\n",
      "2018-04-26 01:31:14,515 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-26 01:31:14,520 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-26 01:31:14,528 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-26 01:31:14,534 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-26 01:31:14,535 : INFO : EPOCH - 3 : training on 1026764 raw words (778235 effective words) took 1.0s, 799565 effective words/s\n",
      "2018-04-26 01:31:15,443 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-26 01:31:15,456 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-26 01:31:15,471 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-26 01:31:15,475 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-26 01:31:15,477 : INFO : EPOCH - 4 : training on 1026764 raw words (778105 effective words) took 0.9s, 829361 effective words/s\n",
      "2018-04-26 01:31:16,506 : INFO : EPOCH 5 - PROGRESS: at 68.15% examples, 586670 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-26 01:31:16,775 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-26 01:31:16,786 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-26 01:31:16,789 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-26 01:31:16,803 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-26 01:31:16,805 : INFO : EPOCH - 5 : training on 1026764 raw words (777897 effective words) took 1.3s, 588703 effective words/s\n",
      "2018-04-26 01:31:16,807 : INFO : training on a 5133820 raw words (3890621 effective words) took 5.8s, 675609 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# print out tracking information\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', \\\n",
    "                    level=logging.INFO)\n",
    "\n",
    "wv_model = word2vec.Word2Vec(sentences, min_count=5, size=200, window=5, workers=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "docs=[TaggedDocument(sentences[i], [str(i)]) for i in range(len(sentences)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dense, Conv1D, MaxPooling1D, \\\n",
    "Dropout, Activation, Input, Flatten, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "              \n",
    "def cnn_model(FILTER_SIZES, \\\n",
    "              # filter sizes as a list\n",
    "              MAX_NB_WORDS, \\\n",
    "              # total number of words\n",
    "              MAX_DOC_LEN, \\\n",
    "              # max words in a doc\n",
    "              EMBEDDING_DIM=200, \\\n",
    "              # word vector dimension\n",
    "              NUM_FILTERS=64, \\\n",
    "              # number of filters for all size\n",
    "              DROP_OUT=0.5, \\\n",
    "              # dropout rate\n",
    "              NUM_OUTPUT_UNITS=1, \\\n",
    "              # number of output units\n",
    "              NUM_DENSE_UNITS=100,\\\n",
    "              # number of units in dense layer\n",
    "              PRETRAINED_WORD_VECTOR=None,\\\n",
    "              # Whether to use pretrained word vectors\n",
    "              LAM=0.0):            \n",
    "              # regularization coefficient\n",
    "    \n",
    "    main_input = Input(shape=(MAX_DOC_LEN,), \\\n",
    "                       dtype='int32', name='main_input')\n",
    "    \n",
    "    if PRETRAINED_WORD_VECTOR is not None:\n",
    "        embed_1 = Embedding(input_dim=MAX_NB_WORDS+1, \\\n",
    "                        output_dim=EMBEDDING_DIM, \\\n",
    "                        input_length=MAX_DOC_LEN, \\\n",
    "                        weights=[PRETRAINED_WORD_VECTOR],\\\n",
    "                        trainable=False,\\\n",
    "                        name='embedding')(main_input)\n",
    "    else:\n",
    "        embed_1 = Embedding(input_dim=MAX_NB_WORDS+1, \\\n",
    "                        output_dim=EMBEDDING_DIM, \\\n",
    "                        input_length=MAX_DOC_LEN, \\\n",
    "                        name='embedding')(main_input)\n",
    "    # add convolution-pooling-flat block\n",
    "    conv_blocks = []\n",
    "    for f in FILTER_SIZES:\n",
    "        conv = Conv1D(filters=NUM_FILTERS, kernel_size=f, \\\n",
    "                      activation='relu', name='conv_'+str(f))(embed_1)\n",
    "        conv = MaxPooling1D(MAX_DOC_LEN-f+1, name='max_'+str(f))(conv)\n",
    "        conv = Flatten(name='flat_'+str(f))(conv)\n",
    "        conv_blocks.append(conv)\n",
    "    \n",
    "    if len(conv_blocks)>1:\n",
    "        z=Concatenate(name='concate')(conv_blocks)\n",
    "    else:\n",
    "        z=conv_blocks[0]\n",
    "        \n",
    "    drop=Dropout(rate=DROP_OUT, name='dropout')(z)\n",
    "\n",
    "    dense = Dense(NUM_DENSE_UNITS, activation='relu',\\\n",
    "                    kernel_regularizer=l2(LAM),name='dense')(drop)\n",
    "    preds = Dense(NUM_OUTPUT_UNITS, activation='sigmoid', name='output')(dense)\n",
    "    model = Model(inputs=main_input, outputs=preds)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", \\\n",
    "              optimizer=\"adam\", metrics=[\"accuracy\"]) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# the file path to save best model\n",
    "BEST_MODEL_FILEPATH=\"best_model\"\n",
    "\n",
    "# define early stopping based on validation loss\n",
    "# if validation loss is not improved in \n",
    "# an iteration compared with the previous one, \n",
    "# stop training (i.e. patience=0). \n",
    "# mode='min' indicate the loss needs to decrease \n",
    "earlyStopping=EarlyStopping(monitor='val_loss', \\\n",
    "                            patience=0, verbose=2, \\\n",
    "                            mode='min')\n",
    "\n",
    "# define checkpoint to save best model\n",
    "# which has max. validation acc\n",
    "checkpoint = ModelCheckpoint(BEST_MODEL_FILEPATH, \\\n",
    "                             monitor='val_acc', \\\n",
    "                             verbose=2, \\\n",
    "                             save_best_only=True, \\\n",
    "                             mode='max')\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=\"binary_crossentropy\", \\\n",
    "              optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1818, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '3'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([923, 454, 441])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from numpy.random import shuffle\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y=mlb.fit_transform(target)  # instead of label it is target\n",
    "# check size of indicator matrix\n",
    "Y.shape\n",
    "# check classes\n",
    "mlb.classes_\n",
    "# check # of samples in each class\n",
    "np.sum(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "import numpy as np\n",
    "\n",
    "# get a Keras tokenizer\n",
    "\n",
    "MAX_NB_WORDS=8000\n",
    "# documents are quite long in the dataset\n",
    "MAX_DOC_LEN=1000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(text)\n",
    "voc=tokenizer.word_index\n",
    "# convert each document to a list of word index as a sequence\n",
    "sequences = tokenizer.texts_to_sequences(text)\n",
    "# get the mapping between words to word index\n",
    "\n",
    "# pad all sequences into the same length (the longest)\n",
    "padded_sequences = pad_sequences(sequences, \\\n",
    "                                 maxlen=MAX_DOC_LEN, \\\n",
    "                                 padding='post', truncating='post')\n",
    "\n",
    "#print(padded_sequences[0])\n",
    "\n",
    "\n",
    "EMBEDDING_DIM=200\n",
    "# get a Keras tokenizer\n",
    "\n",
    "MAX_NB_WORDS=8000\n",
    "# documents are quite long in the dataset\n",
    "MAX_DOC_LEN=1000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(text)\n",
    "# tokenizer.word_index provides the mapping \n",
    "# between a word and word index for all words\n",
    "NUM_WORDS = min(MAX_NB_WORDS, len(tokenizer.word_index))\n",
    "\n",
    "# \"+1\" is for padding symbol\n",
    "embedding_matrix = np.zeros((NUM_WORDS+1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    # if word_index is above the max number of words, ignore it\n",
    "    if i >= NUM_WORDS:\n",
    "        continue\n",
    "    if word in wv_model.wv:\n",
    "        embedding_matrix[i]=wv_model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1818, 1000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1818, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.1164 - acc: 0.9508 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00665, saving model to best_model\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00665 to 0.00637, saving model to best_model\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00637 to 0.00619, saving model to best_model\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00619 to 0.00601, saving model to best_model\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00601 to 0.00584, saving model to best_model\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00584 to 0.00562, saving model to best_model\n",
      "Epoch 7/100\n",
      " - 7s - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00562 to 0.00543, saving model to best_model\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00543 to 0.00522, saving model to best_model\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00522 to 0.00500, saving model to best_model\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00500 to 0.00469, saving model to best_model\n",
      "Epoch 11/100\n",
      " - 6s - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00469 to 0.00438, saving model to best_model\n",
      "Epoch 12/100\n",
      " - 5s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00438 to 0.00406, saving model to best_model\n",
      "Epoch 13/100\n",
      " - 5s - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00406 to 0.00367, saving model to best_model\n",
      "Epoch 14/100\n",
      " - 6s - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00367 to 0.00330, saving model to best_model\n",
      "Epoch 15/100\n",
      " - 5s - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00330 to 0.00295, saving model to best_model\n",
      "Epoch 16/100\n",
      " - 5s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00295 to 0.00267, saving model to best_model\n",
      "Epoch 17/100\n",
      " - 5s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00267 to 0.00229, saving model to best_model\n",
      "Epoch 18/100\n",
      " - 5s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00229 to 0.00196, saving model to best_model\n",
      "Epoch 19/100\n",
      " - 5s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00196 to 0.00164, saving model to best_model\n",
      "Epoch 20/100\n",
      " - 5s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00164 to 0.00138, saving model to best_model\n",
      "Epoch 21/100\n",
      " - 5s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00138 to 0.00120, saving model to best_model\n",
      "Epoch 22/100\n",
      " - 5s - loss: 0.0017 - acc: 1.0000 - val_loss: 9.9231e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00120 to 0.00099, saving model to best_model\n",
      "Epoch 23/100\n",
      " - 6s - loss: 0.0015 - acc: 1.0000 - val_loss: 8.1870e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00099 to 0.00082, saving model to best_model\n",
      "Epoch 24/100\n",
      " - 5s - loss: 0.0013 - acc: 1.0000 - val_loss: 6.5695e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00082 to 0.00066, saving model to best_model\n",
      "Epoch 25/100\n",
      " - 5s - loss: 0.0011 - acc: 1.0000 - val_loss: 5.5641e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00066 to 0.00056, saving model to best_model\n",
      "Epoch 26/100\n",
      " - 6s - loss: 7.2306e-04 - acc: 1.0000 - val_loss: 4.7728e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00056 to 0.00048, saving model to best_model\n",
      "Epoch 27/100\n",
      " - 5s - loss: 6.5230e-04 - acc: 1.0000 - val_loss: 4.1671e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00048 to 0.00042, saving model to best_model\n",
      "Epoch 28/100\n",
      " - 7s - loss: 8.5094e-04 - acc: 1.0000 - val_loss: 3.6462e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00042 to 0.00036, saving model to best_model\n",
      "Epoch 29/100\n",
      " - 6s - loss: 5.3254e-04 - acc: 1.0000 - val_loss: 3.1636e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00036 to 0.00032, saving model to best_model\n",
      "Epoch 30/100\n",
      " - 5s - loss: 4.7732e-04 - acc: 1.0000 - val_loss: 2.7434e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00032 to 0.00027, saving model to best_model\n",
      "Epoch 31/100\n",
      " - 5s - loss: 3.6240e-04 - acc: 1.0000 - val_loss: 2.4359e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00027 to 0.00024, saving model to best_model\n",
      "Epoch 32/100\n",
      " - 6s - loss: 3.6777e-04 - acc: 1.0000 - val_loss: 2.2148e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00024 to 0.00022, saving model to best_model\n",
      "Epoch 33/100\n",
      " - 6s - loss: 3.1614e-04 - acc: 1.0000 - val_loss: 1.9433e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00022 to 0.00019, saving model to best_model\n",
      "Epoch 34/100\n",
      " - 6s - loss: 2.6833e-04 - acc: 1.0000 - val_loss: 1.7647e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00019 to 0.00018, saving model to best_model\n",
      "Epoch 35/100\n",
      " - 6s - loss: 2.8247e-04 - acc: 1.0000 - val_loss: 1.5980e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00018 to 0.00016, saving model to best_model\n",
      "Epoch 36/100\n",
      " - 6s - loss: 2.2789e-04 - acc: 1.0000 - val_loss: 1.4582e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00016 to 0.00015, saving model to best_model\n",
      "Epoch 37/100\n",
      " - 6s - loss: 2.3700e-04 - acc: 1.0000 - val_loss: 1.3431e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00015 to 0.00013, saving model to best_model\n",
      "Epoch 38/100\n",
      " - 6s - loss: 2.4450e-04 - acc: 1.0000 - val_loss: 1.2313e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00013 to 0.00012, saving model to best_model\n",
      "Epoch 39/100\n",
      " - 5s - loss: 3.0541e-04 - acc: 1.0000 - val_loss: 1.0968e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00012 to 0.00011, saving model to best_model\n",
      "Epoch 40/100\n",
      " - 6s - loss: 1.5567e-04 - acc: 1.0000 - val_loss: 1.0171e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00011 to 0.00010, saving model to best_model\n",
      "Epoch 41/100\n",
      " - 6s - loss: 1.6943e-04 - acc: 1.0000 - val_loss: 9.3677e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00010 to 0.00009, saving model to best_model\n",
      "Epoch 42/100\n",
      " - 6s - loss: 1.7563e-04 - acc: 1.0000 - val_loss: 8.5537e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00009 to 0.00009, saving model to best_model\n",
      "Epoch 43/100\n",
      " - 5s - loss: 1.6586e-04 - acc: 1.0000 - val_loss: 7.9576e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00009 to 0.00008, saving model to best_model\n",
      "Epoch 44/100\n",
      " - 5s - loss: 1.1773e-04 - acc: 1.0000 - val_loss: 7.2832e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00008 to 0.00007, saving model to best_model\n",
      "Epoch 45/100\n",
      " - 5s - loss: 1.0572e-04 - acc: 1.0000 - val_loss: 6.6715e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00007 to 0.00007, saving model to best_model\n",
      "Epoch 46/100\n",
      " - 5s - loss: 1.1287e-04 - acc: 1.0000 - val_loss: 6.2503e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00007 to 0.00006, saving model to best_model\n",
      "Epoch 47/100\n",
      " - 5s - loss: 1.1425e-04 - acc: 1.0000 - val_loss: 5.7155e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00006 to 0.00006, saving model to best_model\n",
      "Epoch 48/100\n",
      " - 7s - loss: 9.1261e-05 - acc: 1.0000 - val_loss: 5.4112e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00048: val_loss improved from 0.00006 to 0.00005, saving model to best_model\n",
      "Epoch 49/100\n",
      " - 5s - loss: 9.5295e-05 - acc: 1.0000 - val_loss: 5.0659e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00005 to 0.00005, saving model to best_model\n",
      "Epoch 50/100\n",
      " - 7s - loss: 9.4997e-05 - acc: 1.0000 - val_loss: 4.7661e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00005 to 0.00005, saving model to best_model\n",
      "Epoch 51/100\n",
      " - 5s - loss: 7.9133e-05 - acc: 1.0000 - val_loss: 4.5125e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00005 to 0.00005, saving model to best_model\n",
      "Epoch 52/100\n",
      " - 6s - loss: 7.0321e-05 - acc: 1.0000 - val_loss: 4.2881e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00005 to 0.00004, saving model to best_model\n",
      "Epoch 53/100\n",
      " - 5s - loss: 6.0589e-05 - acc: 1.0000 - val_loss: 4.0913e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00004 to 0.00004, saving model to best_model\n",
      "Epoch 54/100\n",
      " - 5s - loss: 7.8261e-05 - acc: 1.0000 - val_loss: 3.8690e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00004 to 0.00004, saving model to best_model\n",
      "Epoch 55/100\n",
      " - 5s - loss: 4.2225e-05 - acc: 1.0000 - val_loss: 3.7099e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00004 to 0.00004, saving model to best_model\n",
      "Epoch 56/100\n",
      " - 5s - loss: 6.6286e-05 - acc: 1.0000 - val_loss: 3.5509e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00004 to 0.00004, saving model to best_model\n",
      "Epoch 57/100\n",
      " - 5s - loss: 6.5330e-05 - acc: 1.0000 - val_loss: 3.4027e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00004 to 0.00003, saving model to best_model\n",
      "Epoch 58/100\n",
      " - 5s - loss: 3.8524e-05 - acc: 1.0000 - val_loss: 3.2706e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00003 to 0.00003, saving model to best_model\n",
      "Epoch 59/100\n",
      " - 5s - loss: 5.3363e-05 - acc: 1.0000 - val_loss: 3.1057e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00003 to 0.00003, saving model to best_model\n",
      "Epoch 60/100\n",
      " - 6s - loss: 5.6284e-05 - acc: 1.0000 - val_loss: 2.9666e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00003 to 0.00003, saving model to best_model\n",
      "Epoch 61/100\n",
      " - 5s - loss: 4.6273e-05 - acc: 1.0000 - val_loss: 2.8484e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00003 to 0.00003, saving model to best_model\n",
      "Epoch 62/100\n",
      " - 5s - loss: 6.7547e-05 - acc: 1.0000 - val_loss: 2.6993e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00003 to 0.00003, saving model to best_model\n",
      "Epoch 63/100\n",
      " - 5s - loss: 4.0560e-05 - acc: 1.0000 - val_loss: 2.5824e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00003 to 0.00003, saving model to best_model\n",
      "Epoch 64/100\n",
      " - 5s - loss: 6.3685e-05 - acc: 1.0000 - val_loss: 2.4358e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00003 to 0.00002, saving model to best_model\n",
      "Epoch 65/100\n",
      " - 5s - loss: 4.3252e-05 - acc: 1.0000 - val_loss: 2.3356e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 66/100\n",
      " - 6s - loss: 6.5162e-05 - acc: 1.0000 - val_loss: 2.1933e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 67/100\n",
      " - 5s - loss: 4.2346e-05 - acc: 1.0000 - val_loss: 2.0902e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 68/100\n",
      " - 5s - loss: 3.4706e-05 - acc: 1.0000 - val_loss: 2.0036e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 69/100\n",
      " - 5s - loss: 2.8253e-05 - acc: 1.0000 - val_loss: 1.9308e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 70/100\n",
      " - 5s - loss: 2.4791e-05 - acc: 1.0000 - val_loss: 1.8711e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 71/100\n",
      " - 6s - loss: 2.4759e-05 - acc: 1.0000 - val_loss: 1.8186e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 72/100\n",
      " - 6s - loss: 2.7325e-05 - acc: 1.0000 - val_loss: 1.7649e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 73/100\n",
      " - 5s - loss: 3.5743e-05 - acc: 1.0000 - val_loss: 1.7094e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 74/100\n",
      " - 5s - loss: 2.9577e-05 - acc: 1.0000 - val_loss: 1.6439e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 75/100\n",
      " - 5s - loss: 1.8551e-05 - acc: 1.0000 - val_loss: 1.6028e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 76/100\n",
      " - 5s - loss: 1.5125e-05 - acc: 1.0000 - val_loss: 1.5655e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 77/100\n",
      " - 6s - loss: 2.6308e-05 - acc: 1.0000 - val_loss: 1.5145e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00002 to 0.00002, saving model to best_model\n",
      "Epoch 78/100\n",
      " - 5s - loss: 4.9439e-05 - acc: 1.0000 - val_loss: 1.4589e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00002 to 0.00001, saving model to best_model\n",
      "Epoch 79/100\n",
      " - 5s - loss: 2.5459e-05 - acc: 1.0000 - val_loss: 1.3995e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 80/100\n",
      " - 5s - loss: 3.3623e-05 - acc: 1.0000 - val_loss: 1.3518e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 81/100\n",
      " - 6s - loss: 2.7842e-05 - acc: 1.0000 - val_loss: 1.2994e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 82/100\n",
      " - 5s - loss: 2.4954e-05 - acc: 1.0000 - val_loss: 1.2534e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 83/100\n",
      " - 5s - loss: 1.4371e-05 - acc: 1.0000 - val_loss: 1.2223e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 84/100\n",
      " - 6s - loss: 1.5492e-05 - acc: 1.0000 - val_loss: 1.1972e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 85/100\n",
      " - 6s - loss: 1.5872e-05 - acc: 1.0000 - val_loss: 1.1691e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 86/100\n",
      " - 7s - loss: 2.2941e-05 - acc: 1.0000 - val_loss: 1.1344e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 87/100\n",
      " - 6s - loss: 2.0101e-05 - acc: 1.0000 - val_loss: 1.1024e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 88/100\n",
      " - 6s - loss: 2.0139e-05 - acc: 1.0000 - val_loss: 1.0708e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 89/100\n",
      " - 6s - loss: 1.5421e-05 - acc: 1.0000 - val_loss: 1.0408e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 90/100\n",
      " - 7s - loss: 1.4702e-05 - acc: 1.0000 - val_loss: 1.0178e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 91/100\n",
      " - 6s - loss: 1.7092e-05 - acc: 1.0000 - val_loss: 9.9496e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 92/100\n",
      " - 6s - loss: 2.1611e-05 - acc: 1.0000 - val_loss: 9.6818e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 93/100\n",
      " - 5s - loss: 1.4671e-05 - acc: 1.0000 - val_loss: 9.3969e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 94/100\n",
      " - 5s - loss: 2.1161e-05 - acc: 1.0000 - val_loss: 9.1141e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 6s - loss: 1.3228e-05 - acc: 1.0000 - val_loss: 8.9071e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 96/100\n",
      " - 6s - loss: 1.7674e-05 - acc: 1.0000 - val_loss: 8.6513e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 97/100\n",
      " - 6s - loss: 1.0311e-05 - acc: 1.0000 - val_loss: 8.4193e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 98/100\n",
      " - 6s - loss: 1.4824e-05 - acc: 1.0000 - val_loss: 8.2638e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 99/100\n",
      " - 6s - loss: 2.1396e-05 - acc: 1.0000 - val_loss: 7.9831e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n",
      "Epoch 100/100\n",
      " - 6s - loss: 1.7287e-05 - acc: 1.0000 - val_loss: 7.7515e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00001 to 0.00001, saving model to best_model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from numpy.random import shuffle\n",
    "EMBEDDING_DIM=200\n",
    "FILTER_SIZES=[2,3,4]\n",
    "\n",
    "# set the number of output units\n",
    "# as the number of classes\n",
    "#mlb = MultiLabelBinarizer()\n",
    "output_units_num=len(mlb.classes_)\n",
    "\n",
    "#Number of filters for each size\n",
    "num_filters=64\n",
    "\n",
    "# set the dense units\n",
    "dense_units_num= num_filters*len(FILTER_SIZES)\n",
    "\n",
    "BTACH_SIZE = 32\n",
    "NUM_EPOCHES = 100\n",
    "\n",
    "# With well trained word vectors, sample size can be reduced\n",
    "# Assume we only have 500 labeled data\n",
    "# split dataset into train (70%) and test sets (20%)\n",
    "\n",
    "padded_sequences.shape\n",
    "Y.shape\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "                padded_sequences[0:500], Y[0:500], \\\n",
    "                test_size=0.2, random_state=0, shuffle=True)\n",
    "\n",
    "\n",
    "# create the model with embedding matrix\n",
    "model=cnn_model(FILTER_SIZES, MAX_NB_WORDS, \\\n",
    "                MAX_DOC_LEN, \\\n",
    "                NUM_FILTERS=num_filters,\\\n",
    "                NUM_OUTPUT_UNITS=output_units_num, \\\n",
    "                NUM_DENSE_UNITS=dense_units_num,\\\n",
    "                PRETRAINED_WORD_VECTOR=embedding_matrix)\n",
    "\n",
    "earlyStopping=EarlyStopping(monitor='val_loss', patience=1, verbose=2, mode='min')\n",
    "checkpoint = ModelCheckpoint(BEST_MODEL_FILEPATH, monitor='val_loss', \\\n",
    "                             verbose=2, save_best_only=True, mode='min')\n",
    "    \n",
    "training=model.fit(X_train, Y_train, \\\n",
    "          batch_size=BTACH_SIZE, epochs=NUM_EPOCHES, \\\n",
    "          callbacks=[earlyStopping, checkpoint],\\\n",
    "          validation_data=[X_test, Y_test], verbose=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1000, 200)    1600200     main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv1D)                 (None, 999, 64)      25664       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv1D)                 (None, 998, 64)      38464       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv1D)                 (None, 997, 64)      51264       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_2 (MaxPooling1D)            (None, 1, 64)        0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_3 (MaxPooling1D)            (None, 1, 64)        0           conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_4 (MaxPooling1D)            (None, 1, 64)        0           conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flat_2 (Flatten)                (None, 64)           0           max_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flat_3 (Flatten)                (None, 64)           0           max_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flat_4 (Flatten)                (None, 64)           0           max_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concate (Concatenate)           (None, 192)          0           flat_2[0][0]                     \n",
      "                                                                 flat_3[0][0]                     \n",
      "                                                                 flat_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 192)          0           concate[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 192)          37056       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 3)            579         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,753,227\n",
      "Trainable params: 153,027\n",
      "Non-trainable params: 1,600,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      1.00      0.92       423\n",
      "          2       0.00      0.00      0.00        77\n",
      "          3       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.72      0.85      0.78       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "pred=model.predict(padded_sequences[500:1000])\n",
    "\n",
    "Y_pred=np.copy(pred)\n",
    "Y_pred=np.where(Y_pred>0.5,1,0)\n",
    "\n",
    "Y_pred[0:10]\n",
    "Y[500:510]\n",
    "\n",
    "print(classification_report(Y[500:1000], Y_pred, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             freq\n",
      "description   439\n",
      "fis            24\n",
      "provides      478\n",
      "financial     974\n",
      "software     3322\n",
      "   word_freq  count   percent    cumsum\n",
      "0          1   9602  0.313228  0.313228\n",
      "1          2   6318  0.206100  0.519328\n",
      "2          3   2402  0.078356  0.597684\n",
      "3          4   1953  0.063709  0.661393\n",
      "4          5   1008  0.032882  0.694275\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAELCAYAAADX3k30AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkA0Hq0PrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10efb67b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# get count of each word\n",
    "df=pd.DataFrame.from_dict(tokenizer.word_counts, orient=\"index\")\n",
    "df.columns=['freq']\n",
    "print(df.head())\n",
    "\n",
    "# get histogram of word count\n",
    "df=df['freq'].value_counts().reset_index()\n",
    "df.columns=['word_freq','count']\n",
    "\n",
    "# sort by word_freq\n",
    "df=df.sort_values(by='word_freq')\n",
    "\n",
    "# convert absolute counts to precentage\n",
    "df['percent']=df['count']/len(tokenizer.word_counts)\n",
    "# get cumulative percentage\n",
    "df['cumsum']=df['percent'].cumsum()\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df.iloc[0:50].plot(x='word_freq', y='cumsum');\n",
    "\n",
    "plt.show();\n",
    "\n",
    "# if set min count for word to 10, \n",
    "# what % of words can be included?\n",
    "# how many words will be included?\n",
    "# This is the parameter MAX_NB_WORDS\n",
    "# tokenizer = Tokenizer(num_words=MAX_NB_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sent_length  counts   percent    cumsum\n",
      "347            0       2  0.001100  0.001100\n",
      "0              1      49  0.026953  0.028053\n",
      "1              2      13  0.007151  0.035204\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAELCAYAAAAiIMZEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGVU7h2wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1274524e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sen_len=pd.Series([len(item) for item in sequences])\n",
    "\n",
    "# create histogram of sentence length\n",
    "# the \"index\" is the sentence length\n",
    "# \"counts\" is the count of sentences at a length\n",
    "df=sen_len.value_counts().reset_index().sort_values(by='index')\n",
    "df.columns=['sent_length','counts']\n",
    "\n",
    "# sort by sentence length\n",
    "# get percentage and cumulative percentage\n",
    "\n",
    "df['percent']=df['counts']/len(sen_len)\n",
    "df['cumsum']=df['percent'].cumsum()\n",
    "print(df.head(3))\n",
    "\n",
    "# From the plot, 90% sentences have length<500\n",
    "# so it makes sense to set MAX_DOC_LEN=4~500 \n",
    "df.plot(x=\"sent_length\", y='cumsum');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
